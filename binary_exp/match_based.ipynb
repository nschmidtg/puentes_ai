{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e73aa66a-d1f3-4a31-99d1-224485f66339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score, precision_score, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import keras_tuner as kt\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d016ef8-e96f-4e2c-a7eb-294142c1862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('pairs_with_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f76cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a951a2f8-9554-4c0d-9534-292289d82b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "need_emb_cols = [f'need_emb_{i}' for i in range(3072)]\n",
    "res_emb_cols = [f'res_emb_{i}' for i in range(3072)]\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "need_embs = df[need_emb_cols].to_numpy()\n",
    "res_embs = df[res_emb_cols].to_numpy()\n",
    "\n",
    "# Compute cosine similarity row-wise\n",
    "cos_sim = np.einsum('ij,ij->i', need_embs, res_embs) / (\n",
    "    np.linalg.norm(need_embs, axis=1) * np.linalg.norm(res_embs, axis=1) + 1e-9\n",
    ")\n",
    "\n",
    "df['cosine_similarity'] = cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7063d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create richer features\n",
    "df['l2_distance'] = np.linalg.norm(need_embs - res_embs, axis=1)\n",
    "df['dot_product'] = np.einsum('ij,ij->i', need_embs, res_embs)\n",
    "\n",
    "# Optional: elementwise interaction features\n",
    "interaction = need_embs * res_embs\n",
    "interaction_mean = interaction.mean(axis=1)\n",
    "df['interaction_mean'] = interaction_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8ae35c-7b8b-4587-b428-fd939aa6fea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academic_resource_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>Cluster 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321</td>\n",
       "      <td>Sociología_Prácticas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>640</td>\n",
       "      <td>Cluster 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>225</td>\n",
       "      <td>Cluster 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>253</td>\n",
       "      <td>Cluster 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   academic_resource_id                  name\n",
       "0                   391             Cluster 1\n",
       "1                   321  Sociología_Prácticas\n",
       "2                   640             Cluster 2\n",
       "3                   225             Cluster 3\n",
       "4                   253             Cluster 4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = pd.read_csv('clusters.csv')\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5f12e7-a742-404e-91b9-f76a94cb05d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>need_id</th>\n",
       "      <th>need_name</th>\n",
       "      <th>need_description</th>\n",
       "      <th>need_expiration_date</th>\n",
       "      <th>need_created_at</th>\n",
       "      <th>need_internship</th>\n",
       "      <th>offer_name</th>\n",
       "      <th>offer_description</th>\n",
       "      <th>offer_semester</th>\n",
       "      <th>offer_company_year</th>\n",
       "      <th>...</th>\n",
       "      <th>res_emb_3067</th>\n",
       "      <th>res_emb_3068</th>\n",
       "      <th>res_emb_3069</th>\n",
       "      <th>res_emb_3070</th>\n",
       "      <th>res_emb_3071</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>l2_distance</th>\n",
       "      <th>dot_product</th>\n",
       "      <th>interaction_mean</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1456</td>\n",
       "      <td>Investigación sobre los factores que inciden e...</td>\n",
       "      <td>De acuerdo a la temáticas sociales y en especi...</td>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>2019-02-04 14:56:21.388586</td>\n",
       "      <td>True</td>\n",
       "      <td>Pasantía de College 1-2019</td>\n",
       "      <td>Pasantía cocurricular de al menos 160 horas, d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048212</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>-0.013416</td>\n",
       "      <td>-0.028706</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>0.411339</td>\n",
       "      <td>1.085045</td>\n",
       "      <td>0.411339</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>College CCNN_Pasantías</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5168</td>\n",
       "      <td>Apoyo y elaboración de plan de marketing para ...</td>\n",
       "      <td>La Fábrica de Renca es una entidad privada sin...</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>2023-09-20 20:05:59.124840</td>\n",
       "      <td>True</td>\n",
       "      <td>Práctica Profesional 2-2023</td>\n",
       "      <td>Práctica profesional obligatoria de 320 horas ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039514</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.006662</td>\n",
       "      <td>-0.018958</td>\n",
       "      <td>-0.012061</td>\n",
       "      <td>0.486173</td>\n",
       "      <td>1.013733</td>\n",
       "      <td>0.486173</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>Comercial_Prácticas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5152</td>\n",
       "      <td>Taller de Intervención para Programa de Calle ...</td>\n",
       "      <td>El curso taller de intervención tiene como pro...</td>\n",
       "      <td>2024-03-06</td>\n",
       "      <td>2023-09-06 19:51:21.818464</td>\n",
       "      <td>True</td>\n",
       "      <td>Taller de Intervención 2-2023</td>\n",
       "      <td>Taller de intervención dirigido a estudiantes ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049481</td>\n",
       "      <td>-0.002994</td>\n",
       "      <td>-0.004206</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.782764</td>\n",
       "      <td>0.659146</td>\n",
       "      <td>0.782764</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>Trabajo Social_Práctica Inicial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3993</td>\n",
       "      <td>Diagnóstico de la población migrante en Renca ...</td>\n",
       "      <td>Desde el departamento de inclusión de la munic...</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>2022-03-22 13:54:44.014323</td>\n",
       "      <td>True</td>\n",
       "      <td>Pasantía Verano-2021</td>\n",
       "      <td>Pasantía cocurricular de al menos 160 horas, d...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045297</td>\n",
       "      <td>-0.006526</td>\n",
       "      <td>-0.019708</td>\n",
       "      <td>-0.012770</td>\n",
       "      <td>-0.005960</td>\n",
       "      <td>0.520189</td>\n",
       "      <td>0.979603</td>\n",
       "      <td>0.520189</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>Sociología_Prácticas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1907</td>\n",
       "      <td>Práctica Inicial Trabajo Social (II) - Unidad ...</td>\n",
       "      <td>Dentro de los objetivos de la Unidad Técnica d...</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>2019-08-19 14:00:49.570249</td>\n",
       "      <td>True</td>\n",
       "      <td>Práctica Inicial II 2-2019</td>\n",
       "      <td>Segunda parte del taller de intervención dirig...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046884</td>\n",
       "      <td>-0.001429</td>\n",
       "      <td>-0.001713</td>\n",
       "      <td>-0.005516</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0.396248</td>\n",
       "      <td>1.098865</td>\n",
       "      <td>0.396248</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>Trabajo Social_Práctica Inicial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   need_id                                          need_name  \\\n",
       "0     1456  Investigación sobre los factores que inciden e...   \n",
       "1     5168  Apoyo y elaboración de plan de marketing para ...   \n",
       "2     5152  Taller de Intervención para Programa de Calle ...   \n",
       "3     3993  Diagnóstico de la población migrante en Renca ...   \n",
       "4     1907  Práctica Inicial Trabajo Social (II) - Unidad ...   \n",
       "\n",
       "                                    need_description need_expiration_date  \\\n",
       "0  De acuerdo a la temáticas sociales y en especi...           2019-08-04   \n",
       "1  La Fábrica de Renca es una entidad privada sin...           2024-03-20   \n",
       "2  El curso taller de intervención tiene como pro...           2024-03-06   \n",
       "3  Desde el departamento de inclusión de la munic...           2022-09-22   \n",
       "4  Dentro de los objetivos de la Unidad Técnica d...           2020-02-19   \n",
       "\n",
       "              need_created_at  need_internship                     offer_name  \\\n",
       "0  2019-02-04 14:56:21.388586             True     Pasantía de College 1-2019   \n",
       "1  2023-09-20 20:05:59.124840             True    Práctica Profesional 2-2023   \n",
       "2  2023-09-06 19:51:21.818464             True  Taller de Intervención 2-2023   \n",
       "3  2022-03-22 13:54:44.014323             True           Pasantía Verano-2021   \n",
       "4  2019-08-19 14:00:49.570249             True     Práctica Inicial II 2-2019   \n",
       "\n",
       "                                   offer_description  offer_semester  \\\n",
       "0  Pasantía cocurricular de al menos 160 horas, d...             0.0   \n",
       "1  Práctica profesional obligatoria de 320 horas ...             1.0   \n",
       "2  Taller de intervención dirigido a estudiantes ...             1.0   \n",
       "3  Pasantía cocurricular de al menos 160 horas, d...             2.0   \n",
       "4  Segunda parte del taller de intervención dirig...             1.0   \n",
       "\n",
       "   offer_company_year  ... res_emb_3067  res_emb_3068 res_emb_3069  \\\n",
       "0                2019  ...     0.048212      0.003851    -0.013416   \n",
       "1                2023  ...     0.039514     -0.000184    -0.006662   \n",
       "2                2023  ...     0.049481     -0.002994    -0.004206   \n",
       "3                2021  ...     0.045297     -0.006526    -0.019708   \n",
       "4                2019  ...     0.046884     -0.001429    -0.001713   \n",
       "\n",
       "   res_emb_3070 res_emb_3071 cosine_similarity  l2_distance  dot_product  \\\n",
       "0     -0.028706    -0.004475          0.411339     1.085045     0.411339   \n",
       "1     -0.018958    -0.012061          0.486173     1.013733     0.486173   \n",
       "2     -0.003688     0.003104          0.782764     0.659146     0.782764   \n",
       "3     -0.012770    -0.005960          0.520189     0.979603     0.520189   \n",
       "4     -0.005516     0.009988          0.396248     1.098865     0.396248   \n",
       "\n",
       "   interaction_mean                             name  \n",
       "0          0.000134           College CCNN_Pasantías  \n",
       "1          0.000158              Comercial_Prácticas  \n",
       "2          0.000255  Trabajo Social_Práctica Inicial  \n",
       "3          0.000169             Sociología_Prácticas  \n",
       "4          0.000129  Trabajo Social_Práctica Inicial  \n",
       "\n",
       "[5 rows x 6168 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = df.merge(clusters, on=\"academic_resource_id\", how=\"left\")\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62158b9e-58a4-4a61-a2e2-9fb823162950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged\n",
    "df = df.drop(columns=['academic_resource_description','need_id','need_name','need_description','need_expiration_date','need_created_at','offer_description','offer_name','offer_semester','offer_company_year','offer_expiration_date','offer_academic_resource_id','offer_created_at','academic_resource_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b86583-d26b-4d35-8a1b-b8a42cf921da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"need_internship\"] = df[\"need_internship\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c727b359-b756-4075-aeaa-7e93f9651eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 6154)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4739867-24aa-436e-9c70-d8a3e90a9650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>need_internship</th>\n",
       "      <th>academic_resource_id</th>\n",
       "      <th>academic_resource_level</th>\n",
       "      <th>academic_resource_type_id</th>\n",
       "      <th>has_match</th>\n",
       "      <th>need_emb_0</th>\n",
       "      <th>need_emb_1</th>\n",
       "      <th>need_emb_2</th>\n",
       "      <th>need_emb_3</th>\n",
       "      <th>need_emb_4</th>\n",
       "      <th>...</th>\n",
       "      <th>res_emb_3067</th>\n",
       "      <th>res_emb_3068</th>\n",
       "      <th>res_emb_3069</th>\n",
       "      <th>res_emb_3070</th>\n",
       "      <th>res_emb_3071</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>l2_distance</th>\n",
       "      <th>dot_product</th>\n",
       "      <th>interaction_mean</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011038</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>-0.007517</td>\n",
       "      <td>-0.016986</td>\n",
       "      <td>0.014604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048212</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>-0.013416</td>\n",
       "      <td>-0.028706</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>0.411339</td>\n",
       "      <td>1.085045</td>\n",
       "      <td>0.411339</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>College CCNN_Pasantías</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.008638</td>\n",
       "      <td>0.036582</td>\n",
       "      <td>-0.013364</td>\n",
       "      <td>-0.018138</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039514</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.006662</td>\n",
       "      <td>-0.018958</td>\n",
       "      <td>-0.012061</td>\n",
       "      <td>0.486173</td>\n",
       "      <td>1.013733</td>\n",
       "      <td>0.486173</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>Comercial_Prácticas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>582</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.034407</td>\n",
       "      <td>-0.001854</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.020503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049481</td>\n",
       "      <td>-0.002994</td>\n",
       "      <td>-0.004206</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.782764</td>\n",
       "      <td>0.659146</td>\n",
       "      <td>0.782764</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>Trabajo Social_Práctica Inicial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007967</td>\n",
       "      <td>0.022626</td>\n",
       "      <td>-0.013080</td>\n",
       "      <td>-0.032534</td>\n",
       "      <td>0.038485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045297</td>\n",
       "      <td>-0.006526</td>\n",
       "      <td>-0.019708</td>\n",
       "      <td>-0.012770</td>\n",
       "      <td>-0.005960</td>\n",
       "      <td>0.520189</td>\n",
       "      <td>0.979603</td>\n",
       "      <td>0.520189</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>Sociología_Prácticas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>-0.005712</td>\n",
       "      <td>-0.003436</td>\n",
       "      <td>-0.047204</td>\n",
       "      <td>0.015465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046884</td>\n",
       "      <td>-0.001429</td>\n",
       "      <td>-0.001713</td>\n",
       "      <td>-0.005516</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0.396248</td>\n",
       "      <td>1.098865</td>\n",
       "      <td>0.396248</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>Trabajo Social_Práctica Inicial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   need_internship  academic_resource_id  academic_resource_level  \\\n",
       "0                1                   250                        1   \n",
       "1                1                   205                        2   \n",
       "2                1                   582                        1   \n",
       "3                1                   330                        2   \n",
       "4                1                   286                        1   \n",
       "\n",
       "   academic_resource_type_id  has_match  need_emb_0  need_emb_1  need_emb_2  \\\n",
       "0                         24          1   -0.011038    0.009111   -0.007517   \n",
       "1                         21          1   -0.008638    0.036582   -0.013364   \n",
       "2                         21          1    0.010936    0.034407   -0.001854   \n",
       "3                         24          1   -0.007967    0.022626   -0.013080   \n",
       "4                         21          1    0.002075   -0.005712   -0.003436   \n",
       "\n",
       "   need_emb_3  need_emb_4  ...  res_emb_3067  res_emb_3068  res_emb_3069  \\\n",
       "0   -0.016986    0.014604  ...      0.048212      0.003851     -0.013416   \n",
       "1   -0.018138    0.011307  ...      0.039514     -0.000184     -0.006662   \n",
       "2    0.008706    0.020503  ...      0.049481     -0.002994     -0.004206   \n",
       "3   -0.032534    0.038485  ...      0.045297     -0.006526     -0.019708   \n",
       "4   -0.047204    0.015465  ...      0.046884     -0.001429     -0.001713   \n",
       "\n",
       "   res_emb_3070  res_emb_3071  cosine_similarity  l2_distance  dot_product  \\\n",
       "0     -0.028706     -0.004475           0.411339     1.085045     0.411339   \n",
       "1     -0.018958     -0.012061           0.486173     1.013733     0.486173   \n",
       "2     -0.003688      0.003104           0.782764     0.659146     0.782764   \n",
       "3     -0.012770     -0.005960           0.520189     0.979603     0.520189   \n",
       "4     -0.005516      0.009988           0.396248     1.098865     0.396248   \n",
       "\n",
       "   interaction_mean                             name  \n",
       "0          0.000134           College CCNN_Pasantías  \n",
       "1          0.000158              Comercial_Prácticas  \n",
       "2          0.000255  Trabajo Social_Práctica Inicial  \n",
       "3          0.000169             Sociología_Prácticas  \n",
       "4          0.000129  Trabajo Social_Práctica Inicial  \n",
       "\n",
       "[5 rows x 6154 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc6e4bad-5e12-4565-9a97-c924034462ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy categories columns\n",
    "categorical_cols = ['academic_resource_id','academic_resource_level','academic_resource_type_id','name']\n",
    "df_dummies = pd.get_dummies(df, columns=categorical_cols)\n",
    "df_dummies\n",
    "df = df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50e91f00-1ffd-4808-b84d-e09e6c3a9cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['has_match'])\n",
    "y = df['has_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df9ea7d3-e3e5-4138-8c3e-d6c3647db04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Split the data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6843193-1d15-4317-86eb-d9aeb3a92c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# Use the same scaler to transform the validation and test sets\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "967aaaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original training data: (68108, 6664)\n",
      "Shape of resampled training data: (129362, 6664)\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Shape of original training data:\", X_train_scaled.shape)\n",
    "print(\"Shape of resampled training data:\", X_train_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad360622-6098-4c09-9d12-38242d108e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 1.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e14fbd57-ec29-4c66-9716-c11e67b6ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_pr_auc\", mode=\"max\", patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_pr_auc\", mode=\"max\", factor=0.5, patience=2, verbose=1),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "955b70a0-3b87-45b5-a885-29512d64d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Build the model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_resampled.shape[1],)),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(1, activation='sigmoid')  # clasificación binaria\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c7f18c-f225-4821-8bf8-a854021093de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               853120    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 128)               512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 862209 (3.29 MB)\n",
      "Trainable params: 861825 (3.29 MB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pr_auc = AUC(curve=\"PR\", name=\"pr_auc\")\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[Precision(name=\"precision\"), Recall(name=\"recall\"), AUC(name=\"auc\"), pr_auc],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "debbd185-525a-4d05-9bde-202bff7229be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4043/4043 [==============================] - 10s 2ms/step - loss: 0.2534 - precision: 0.8846 - recall: 0.9143 - auc: 0.9605 - pr_auc: 0.9556 - val_loss: 0.1726 - val_precision: 0.3784 - val_recall: 0.7726 - val_auc: 0.9528 - val_pr_auc: 0.6192 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.1404 - precision: 0.9388 - recall: 0.9598 - auc: 0.9866 - pr_auc: 0.9832 - val_loss: 0.1355 - val_precision: 0.4864 - val_recall: 0.7433 - val_auc: 0.9539 - val_pr_auc: 0.6409 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.1121 - precision: 0.9522 - recall: 0.9697 - auc: 0.9909 - pr_auc: 0.9882 - val_loss: 0.1337 - val_precision: 0.5041 - val_recall: 0.7457 - val_auc: 0.9510 - val_pr_auc: 0.6582 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0972 - precision: 0.9597 - recall: 0.9732 - auc: 0.9928 - pr_auc: 0.9906 - val_loss: 0.1332 - val_precision: 0.5077 - val_recall: 0.7262 - val_auc: 0.9470 - val_pr_auc: 0.6522 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0868 - precision: 0.9641 - recall: 0.9761 - auc: 0.9940 - pr_auc: 0.9920 - val_loss: 0.1240 - val_precision: 0.5465 - val_recall: 0.7188 - val_auc: 0.9473 - val_pr_auc: 0.6639 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0775 - precision: 0.9684 - recall: 0.9789 - auc: 0.9951 - pr_auc: 0.9934 - val_loss: 0.1271 - val_precision: 0.5631 - val_recall: 0.7090 - val_auc: 0.9436 - val_pr_auc: 0.6530 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0721 - precision: 0.9708 - recall: 0.9803 - auc: 0.9955 - pr_auc: 0.9937 - val_loss: 0.1289 - val_precision: 0.5639 - val_recall: 0.7335 - val_auc: 0.9448 - val_pr_auc: 0.6697 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0695 - precision: 0.9717 - recall: 0.9817 - auc: 0.9958 - pr_auc: 0.9942 - val_loss: 0.1265 - val_precision: 0.5822 - val_recall: 0.7017 - val_auc: 0.9434 - val_pr_auc: 0.6377 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "4032/4043 [============================>.] - ETA: 0s - loss: 0.0647 - precision: 0.9741 - recall: 0.9827 - auc: 0.9963 - pr_auc: 0.9948\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0648 - precision: 0.9740 - recall: 0.9827 - auc: 0.9963 - pr_auc: 0.9948 - val_loss: 0.1211 - val_precision: 0.5921 - val_recall: 0.6993 - val_auc: 0.9388 - val_pr_auc: 0.6580 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0516 - precision: 0.9783 - recall: 0.9877 - auc: 0.9974 - pr_auc: 0.9963 - val_loss: 0.1256 - val_precision: 0.5923 - val_recall: 0.6748 - val_auc: 0.9408 - val_pr_auc: 0.6502 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "4041/4043 [============================>.] - ETA: 0s - loss: 0.0477 - precision: 0.9809 - recall: 0.9883 - auc: 0.9977 - pr_auc: 0.9965\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0477 - precision: 0.9809 - recall: 0.9883 - auc: 0.9977 - pr_auc: 0.9965 - val_loss: 0.1241 - val_precision: 0.6342 - val_recall: 0.6528 - val_auc: 0.9329 - val_pr_auc: 0.6514 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0414 - precision: 0.9836 - recall: 0.9905 - auc: 0.9981 - pr_auc: 0.9972 - val_loss: 0.1279 - val_precision: 0.6138 - val_recall: 0.6528 - val_auc: 0.9305 - val_pr_auc: 0.6500 - lr: 2.5000e-05\n"
     ]
    }
   ],
   "source": [
    "# 8. Train the model\n",
    "history = model.fit(\n",
    "    X_train_resampled, y_train_resampled,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    # class_weight=class_weight_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069dc5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c25ed5c-7800-416b-9c5f-a179f5c8e6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 0s 1ms/step - loss: 0.1065 - pr_auc: 0.6795\n",
      "[0.10650473833084106, 0.6794958710670471]\n"
     ]
    }
   ],
   "source": [
    "# 9. Evaluate the model\n",
    "metrics = model.evaluate(X_test_scaled, y_test)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38ce16a5-dd84-4ce4-9279-e1e4f2452834",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_precision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Precision\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# plt.plot(history.history['precision'], label='Train Precision')\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_precision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Precision\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Recall\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# plt.plot(history.history['recall'], label='Train Recall')\u001b[39;00m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_recall\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Recall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_precision'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10. Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Precision\n",
    "# plt.plot(history.history['precision'], label='Train Precision')\n",
    "plt.plot(history.history['val_precision'], label='Val Precision')\n",
    "\n",
    "# Recall\n",
    "# plt.plot(history.history['recall'], label='Train Recall')\n",
    "plt.plot(history.history['val_recall'], label='Val Recall')\n",
    "\n",
    "# PR-AUC\n",
    "# plt.plot(history.history['pr_auc'], label='Train PR-AUC')\n",
    "plt.plot(history.history['val_pr_auc'], label='Val PR-AUC')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Training History (Precision, Recall, PR-AUC)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2673525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 0s 1ms/step\n",
      "Best threshold for F2: 0.039908856\n",
      "Precision: 0.42396907216494845 Recall: 0.80440097799511 F2: 0.6820066332263983\n"
     ]
    }
   ],
   "source": [
    "y_probs = model.predict(X_val_scaled)\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_probs)\n",
    "f2_scores = (5 * prec * rec) / (4 * prec + rec + 1e-9)\n",
    "best_idx = np.argmax(f2_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "print(\"Best threshold for F2:\", best_threshold)\n",
    "print(\"Precision:\", prec[best_idx], \"Recall:\", rec[best_idx], \"F2:\", f2_scores[best_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3b40b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.00, Precision: 0.05, Recall: 1.00, PR AUC: 0.68\n",
      "Threshold: 0.01, Precision: 0.30, Recall: 0.88, PR AUC: 0.68\n",
      "Threshold: 0.02, Precision: 0.36, Recall: 0.84, PR AUC: 0.68\n",
      "Threshold: 0.03, Precision: 0.40, Recall: 0.82, PR AUC: 0.68\n",
      "Threshold: 0.04, Precision: 0.42, Recall: 0.80, PR AUC: 0.68\n",
      "Threshold: 0.05, Precision: 0.44, Recall: 0.78, PR AUC: 0.68\n",
      "Threshold: 0.06, Precision: 0.46, Recall: 0.76, PR AUC: 0.68\n",
      "Threshold: 0.07, Precision: 0.48, Recall: 0.75, PR AUC: 0.68\n",
      "Threshold: 0.08, Precision: 0.49, Recall: 0.74, PR AUC: 0.68\n",
      "Threshold: 0.09, Precision: 0.51, Recall: 0.74, PR AUC: 0.68\n",
      "Threshold: 0.10, Precision: 0.52, Recall: 0.72, PR AUC: 0.68\n",
      "Threshold: 0.11, Precision: 0.53, Recall: 0.71, PR AUC: 0.68\n",
      "Threshold: 0.12, Precision: 0.54, Recall: 0.71, PR AUC: 0.68\n",
      "Threshold: 0.13, Precision: 0.55, Recall: 0.71, PR AUC: 0.68\n",
      "Threshold: 0.14, Precision: 0.55, Recall: 0.70, PR AUC: 0.68\n",
      "Threshold: 0.15, Precision: 0.57, Recall: 0.70, PR AUC: 0.68\n",
      "Threshold: 0.16, Precision: 0.57, Recall: 0.69, PR AUC: 0.68\n",
      "Threshold: 0.17, Precision: 0.58, Recall: 0.68, PR AUC: 0.68\n",
      "Threshold: 0.18, Precision: 0.58, Recall: 0.67, PR AUC: 0.68\n",
      "Threshold: 0.19, Precision: 0.59, Recall: 0.67, PR AUC: 0.68\n",
      "Threshold: 0.20, Precision: 0.59, Recall: 0.67, PR AUC: 0.68\n",
      "Threshold: 0.21, Precision: 0.60, Recall: 0.66, PR AUC: 0.68\n",
      "Threshold: 0.22, Precision: 0.60, Recall: 0.66, PR AUC: 0.68\n",
      "Threshold: 0.23, Precision: 0.61, Recall: 0.66, PR AUC: 0.68\n",
      "Threshold: 0.24, Precision: 0.61, Recall: 0.66, PR AUC: 0.68\n",
      "Threshold: 0.25, Precision: 0.62, Recall: 0.65, PR AUC: 0.68\n",
      "Threshold: 0.26, Precision: 0.62, Recall: 0.65, PR AUC: 0.68\n",
      "Threshold: 0.27, Precision: 0.63, Recall: 0.64, PR AUC: 0.68\n",
      "Threshold: 0.28, Precision: 0.63, Recall: 0.64, PR AUC: 0.68\n",
      "Threshold: 0.29, Precision: 0.64, Recall: 0.64, PR AUC: 0.68\n",
      "Threshold: 0.30, Precision: 0.64, Recall: 0.63, PR AUC: 0.68\n",
      "Threshold: 0.31, Precision: 0.64, Recall: 0.63, PR AUC: 0.68\n",
      "Threshold: 0.32, Precision: 0.65, Recall: 0.62, PR AUC: 0.68\n",
      "Threshold: 0.33, Precision: 0.65, Recall: 0.62, PR AUC: 0.68\n",
      "Threshold: 0.34, Precision: 0.65, Recall: 0.62, PR AUC: 0.68\n",
      "Threshold: 0.35, Precision: 0.66, Recall: 0.62, PR AUC: 0.68\n",
      "Threshold: 0.36, Precision: 0.66, Recall: 0.61, PR AUC: 0.68\n",
      "Threshold: 0.37, Precision: 0.67, Recall: 0.61, PR AUC: 0.68\n",
      "Threshold: 0.38, Precision: 0.67, Recall: 0.61, PR AUC: 0.68\n",
      "Threshold: 0.39, Precision: 0.67, Recall: 0.61, PR AUC: 0.68\n",
      "Threshold: 0.40, Precision: 0.68, Recall: 0.60, PR AUC: 0.68\n",
      "Threshold: 0.41, Precision: 0.69, Recall: 0.60, PR AUC: 0.68\n",
      "Threshold: 0.42, Precision: 0.69, Recall: 0.60, PR AUC: 0.68\n",
      "Threshold: 0.43, Precision: 0.69, Recall: 0.60, PR AUC: 0.68\n",
      "Threshold: 0.44, Precision: 0.70, Recall: 0.59, PR AUC: 0.68\n",
      "Threshold: 0.45, Precision: 0.70, Recall: 0.59, PR AUC: 0.68\n",
      "Threshold: 0.46, Precision: 0.70, Recall: 0.59, PR AUC: 0.68\n",
      "Threshold: 0.47, Precision: 0.71, Recall: 0.59, PR AUC: 0.68\n",
      "Threshold: 0.48, Precision: 0.71, Recall: 0.59, PR AUC: 0.68\n",
      "Threshold: 0.49, Precision: 0.72, Recall: 0.58, PR AUC: 0.68\n",
      "Threshold: 0.50, Precision: 0.73, Recall: 0.58, PR AUC: 0.68\n",
      "Threshold: 0.51, Precision: 0.72, Recall: 0.57, PR AUC: 0.68\n",
      "Threshold: 0.52, Precision: 0.72, Recall: 0.57, PR AUC: 0.68\n",
      "Threshold: 0.53, Precision: 0.73, Recall: 0.56, PR AUC: 0.68\n",
      "Threshold: 0.54, Precision: 0.73, Recall: 0.56, PR AUC: 0.68\n",
      "Threshold: 0.55, Precision: 0.73, Recall: 0.56, PR AUC: 0.68\n",
      "Threshold: 0.56, Precision: 0.73, Recall: 0.56, PR AUC: 0.68\n",
      "Threshold: 0.57, Precision: 0.74, Recall: 0.56, PR AUC: 0.68\n",
      "Threshold: 0.58, Precision: 0.75, Recall: 0.55, PR AUC: 0.68\n",
      "Threshold: 0.59, Precision: 0.75, Recall: 0.55, PR AUC: 0.68\n",
      "Threshold: 0.60, Precision: 0.75, Recall: 0.55, PR AUC: 0.68\n",
      "Threshold: 0.61, Precision: 0.75, Recall: 0.54, PR AUC: 0.68\n",
      "Threshold: 0.62, Precision: 0.76, Recall: 0.54, PR AUC: 0.68\n",
      "Threshold: 0.63, Precision: 0.76, Recall: 0.53, PR AUC: 0.68\n",
      "Threshold: 0.64, Precision: 0.76, Recall: 0.52, PR AUC: 0.68\n",
      "Threshold: 0.65, Precision: 0.77, Recall: 0.52, PR AUC: 0.68\n",
      "Threshold: 0.66, Precision: 0.76, Recall: 0.51, PR AUC: 0.68\n",
      "Threshold: 0.67, Precision: 0.77, Recall: 0.50, PR AUC: 0.68\n",
      "Threshold: 0.68, Precision: 0.77, Recall: 0.50, PR AUC: 0.68\n",
      "Threshold: 0.69, Precision: 0.77, Recall: 0.50, PR AUC: 0.68\n",
      "Threshold: 0.70, Precision: 0.78, Recall: 0.49, PR AUC: 0.68\n",
      "Threshold: 0.71, Precision: 0.78, Recall: 0.49, PR AUC: 0.68\n",
      "Threshold: 0.72, Precision: 0.79, Recall: 0.47, PR AUC: 0.68\n",
      "Threshold: 0.73, Precision: 0.80, Recall: 0.47, PR AUC: 0.68\n",
      "Threshold: 0.74, Precision: 0.80, Recall: 0.46, PR AUC: 0.68\n",
      "Threshold: 0.75, Precision: 0.80, Recall: 0.46, PR AUC: 0.68\n",
      "Threshold: 0.76, Precision: 0.81, Recall: 0.45, PR AUC: 0.68\n",
      "Threshold: 0.77, Precision: 0.81, Recall: 0.44, PR AUC: 0.68\n",
      "Threshold: 0.78, Precision: 0.81, Recall: 0.43, PR AUC: 0.68\n",
      "Threshold: 0.79, Precision: 0.81, Recall: 0.42, PR AUC: 0.68\n",
      "Threshold: 0.80, Precision: 0.82, Recall: 0.41, PR AUC: 0.68\n",
      "Threshold: 0.81, Precision: 0.82, Recall: 0.41, PR AUC: 0.68\n",
      "Threshold: 0.82, Precision: 0.82, Recall: 0.39, PR AUC: 0.68\n",
      "Threshold: 0.83, Precision: 0.82, Recall: 0.38, PR AUC: 0.68\n",
      "Threshold: 0.84, Precision: 0.82, Recall: 0.38, PR AUC: 0.68\n",
      "Threshold: 0.85, Precision: 0.82, Recall: 0.37, PR AUC: 0.68\n",
      "Threshold: 0.86, Precision: 0.83, Recall: 0.36, PR AUC: 0.68\n",
      "Threshold: 0.87, Precision: 0.83, Recall: 0.35, PR AUC: 0.68\n",
      "Threshold: 0.88, Precision: 0.83, Recall: 0.34, PR AUC: 0.68\n",
      "Threshold: 0.89, Precision: 0.84, Recall: 0.32, PR AUC: 0.68\n",
      "Threshold: 0.90, Precision: 0.84, Recall: 0.32, PR AUC: 0.68\n",
      "Threshold: 0.91, Precision: 0.85, Recall: 0.31, PR AUC: 0.68\n",
      "Threshold: 0.92, Precision: 0.85, Recall: 0.29, PR AUC: 0.68\n",
      "Threshold: 0.93, Precision: 0.86, Recall: 0.27, PR AUC: 0.68\n",
      "Threshold: 0.94, Precision: 0.87, Recall: 0.25, PR AUC: 0.68\n",
      "Threshold: 0.95, Precision: 0.88, Recall: 0.23, PR AUC: 0.68\n",
      "Threshold: 0.96, Precision: 0.92, Recall: 0.21, PR AUC: 0.68\n",
      "Threshold: 0.97, Precision: 0.92, Recall: 0.20, PR AUC: 0.68\n",
      "Threshold: 0.98, Precision: 0.94, Recall: 0.15, PR AUC: 0.68\n",
      "Threshold: 0.99, Precision: 0.96, Recall: 0.11, PR AUC: 0.68\n"
     ]
    }
   ],
   "source": [
    "for thr in np.arange(0, 1.0, 0.01):\n",
    "    y_pred = (y_probs >= thr).astype(int)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    pr_auc = average_precision_score(y_val, y_probs)\n",
    "    print(f\"Threshold: {thr:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, PR AUC: {pr_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0dff588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 0s 1ms/step\n",
      "[[7627  454]\n",
      " [  75  358]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97      8081\n",
      "           1       0.44      0.83      0.58       433\n",
      "\n",
      "    accuracy                           0.94      8514\n",
      "   macro avg       0.72      0.89      0.77      8514\n",
      "weighted avg       0.96      0.94      0.95      8514\n",
      "\n",
      "PR AUC: 0.6881051606796489\n"
     ]
    }
   ],
   "source": [
    "y_probs = model.predict(X_test_scaled)\n",
    "y_pred = (y_probs > 0.04).astype(\"int32\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "pr_auc = average_precision_score(y_test, y_probs)\n",
    "print(\"PR AUC:\", pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dec15eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: model_prauc_0.688_thresh_0.040_prec_0.424_rec_0.804.keras\n",
      "Saving scaler to: scaler_prauc_0.688_thresh_0.040_prec_0.424_rec_0.804.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler_prauc_0.688_thresh_0.040_prec_0.424_rec_0.804.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_filename = (\n",
    "    f\"prauc_{pr_auc:.3f}_\"\n",
    "    f\"thresh_{best_threshold:.3f}_\"\n",
    "    f\"prec_{prec[best_idx]:.3f}_\"\n",
    "    f\"rec_{rec[best_idx]:.3f}\"\n",
    ")\n",
    "\n",
    "model_filename = f\"model_{base_filename}.keras\"\n",
    "scaler_filename = f\"scaler_{base_filename}.pkl\"\n",
    "\n",
    "print(f\"Saving model to: {model_filename}\")\n",
    "model.save(model_filename)\n",
    "print(f\"Saving scaler to: {scaler_filename}\")\n",
    "joblib.dump(scaler, scaler_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "855e2a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a .txt with the hyperpameters with the same name as the model and scaler\n",
    "hyperparams = f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "Optimal units in first layer: {best_hps.get('units_1')}\n",
    "Optimal dropout in first layer: {best_hps.get('dropout_1')}\n",
    "Optimal units in second layer: {best_hps.get('units_2')}\n",
    "Optimal dropout in second layer: {best_hps.get('dropout_2')}\n",
    "Optimal units in third layer: {best_hps.get('units_3')}\n",
    "Optimal dropout in third layer: {best_hps.get('dropout_3')}\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}\n",
    "\n",
    "\"\"\"\n",
    "with open(f\"hyperparams_{base_filename}.txt\", \"w\") as f:\n",
    "    f.write(hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 05m 26s]\n",
      "val_pr_auc: 0.693337619304657\n",
      "\n",
      "Best val_pr_auc So Far: 0.6952050924301147\n",
      "Total elapsed time: 00h 42m 25s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bprint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Get the optimal hyperparameters\u001b[39;00m\n\u001b[1;32m     63\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 65\u001b[0m \u001b[43mbprint\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124mThe hyperparameter search is complete.\u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124mOptimal units in first layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_hps\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits_1\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124mOptimal dropout in first layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_hps\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_1\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124mOptimal units in second layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_hps\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits_2\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124mOptimal dropout in second layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_hps\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_2\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124mOptimal learning rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_hps\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Build the model with the optimal hyperparameters and train it\u001b[39;00m\n\u001b[1;32m     75\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mbuild(best_hps)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bprint' is not defined"
     ]
    }
   ],
   "source": [
    "# First, install KerasTuner\n",
    "# !pip install keras-tuner\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "# 1. Create a model-building function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    hp_units_1 = hp.Int('units_1', min_value=32, max_value=1024, step=32)\n",
    "    model.add(Dense(units=hp_units_1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # Tune the dropout rate\n",
    "    hp_dropout_1 = hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(hp_dropout_1))\n",
    "\n",
    "    # Add another tunable hidden layer\n",
    "    hp_units_2 = hp.Int('units_2', min_value=32, max_value=256, step=32)\n",
    "    model.add(Dense(units=hp_units_2, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    hp_dropout_2 = hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(hp_dropout_2))\n",
    "\n",
    "    # Add another tunable hidden layer\n",
    "    hp_units_3 = hp.Int('units_3', min_value=32, max_value=128, step=32)\n",
    "    model.add(Dense(units=hp_units_3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    hp_dropout_3 = hp.Float('dropout_3', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(hp_dropout_3))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "    \n",
    "    pr_auc = AUC(curve=\"PR\", name=\"pr_auc\")\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[pr_auc])\n",
    "    return model\n",
    "\n",
    "# 2. Instantiate the tuner\n",
    "# We'll use Hyperband, an efficient algorithm for finding good hyperparameters\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective=kt.Objective(\"val_pr_auc\", direction=\"max\"), # Your key metric\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='models',\n",
    "                     project_name='match_tuning')\n",
    "\n",
    "# Define an early stopping callback to prevent wasting time on bad trials\n",
    "stop_early = EarlyStopping(monitor='val_pr_auc', mode='max', patience=5)\n",
    "\n",
    "# 3. Run the search\n",
    "tuner.search(X_train_scaled, y_train,\n",
    "             epochs=50,\n",
    "             validation_data=(X_val_scaled, y_val),\n",
    "             callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "Optimal units in first layer: {best_hps.get('units_1')}\n",
    "Optimal dropout in first layer: {best_hps.get('dropout_1')}\n",
    "Optimal units in second layer: {best_hps.get('units_2')}\n",
    "Optimal dropout in second layer: {best_hps.get('dropout_2')}\n",
    "Optimal units in third layer: {best_hps.get('units_3')}\n",
    "Optimal dropout in third layer: {best_hps.get('dropout_3')}\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7d1938f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete.\n",
      "Optimal units in first layer: 352\n",
      "Optimal dropout in first layer: 0.2\n",
      "Optimal units in second layer: 96\n",
      "Optimal dropout in second layer: 0.2\n",
      "Optimal units in third layer: 64\n",
      "Optimal dropout in third layer: 0.30000000000000004\n",
      "Optimal learning rate: 0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "Optimal units in first layer: {best_hps.get('units_1')}\n",
    "Optimal dropout in first layer: {best_hps.get('dropout_1')}\n",
    "Optimal units in second layer: {best_hps.get('units_2')}\n",
    "Optimal dropout in second layer: {best_hps.get('dropout_2')}\n",
    "Optimal units in third layer: {best_hps.get('units_3')}\n",
    "Optimal dropout in third layer: {best_hps.get('dropout_3')}\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "228e9eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete.\n",
      "Optimal units in first layer: 352\n",
      "Optimal dropout in first layer: 0.2\n",
      "Optimal units in second layer: 96\n",
      "Optimal dropout in second layer: 0.2\n",
      "Optimal units in third layer: 64\n",
      "Optimal dropout in third layer: 0.30000000000000004\n",
      "Optimal learning rate: 0.0001\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "2129/2129 [==============================] - 8s 4ms/step - loss: 0.4906 - pr_auc: 0.0885 - val_loss: 0.1957 - val_pr_auc: 0.3709\n",
      "Epoch 2/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.2045 - pr_auc: 0.2145 - val_loss: 0.1299 - val_pr_auc: 0.4692\n",
      "Epoch 3/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.1523 - pr_auc: 0.3603 - val_loss: 0.1113 - val_pr_auc: 0.5435\n",
      "Epoch 4/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.1347 - pr_auc: 0.4424 - val_loss: 0.1053 - val_pr_auc: 0.5909\n",
      "Epoch 5/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.1170 - pr_auc: 0.5451 - val_loss: 0.1027 - val_pr_auc: 0.5987\n",
      "Epoch 6/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.1067 - pr_auc: 0.5969 - val_loss: 0.0949 - val_pr_auc: 0.6523\n",
      "Epoch 7/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0982 - pr_auc: 0.6434 - val_loss: 0.0940 - val_pr_auc: 0.6415\n",
      "Epoch 8/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0910 - pr_auc: 0.6812 - val_loss: 0.0932 - val_pr_auc: 0.6651\n",
      "Epoch 9/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0872 - pr_auc: 0.7023 - val_loss: 0.0951 - val_pr_auc: 0.6566\n",
      "Epoch 10/50\n",
      "2129/2129 [==============================] - 7s 4ms/step - loss: 0.0796 - pr_auc: 0.7435 - val_loss: 0.0920 - val_pr_auc: 0.6674\n",
      "Epoch 11/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0763 - pr_auc: 0.7634 - val_loss: 0.0959 - val_pr_auc: 0.6689\n",
      "Epoch 12/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0708 - pr_auc: 0.7838 - val_loss: 0.0955 - val_pr_auc: 0.6660\n",
      "Epoch 13/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0678 - pr_auc: 0.8017 - val_loss: 0.1000 - val_pr_auc: 0.6585\n",
      "Epoch 14/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0665 - pr_auc: 0.8050 - val_loss: 0.0974 - val_pr_auc: 0.6663\n",
      "Epoch 15/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0629 - pr_auc: 0.8245 - val_loss: 0.0968 - val_pr_auc: 0.6726\n",
      "Epoch 16/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0597 - pr_auc: 0.8386 - val_loss: 0.0966 - val_pr_auc: 0.6754\n",
      "Epoch 17/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0573 - pr_auc: 0.8502 - val_loss: 0.0985 - val_pr_auc: 0.6725\n",
      "Epoch 18/50\n",
      "2129/2129 [==============================] - 8s 4ms/step - loss: 0.0558 - pr_auc: 0.8549 - val_loss: 0.0977 - val_pr_auc: 0.6844\n",
      "Epoch 19/50\n",
      "2129/2129 [==============================] - 8s 4ms/step - loss: 0.0531 - pr_auc: 0.8671 - val_loss: 0.0970 - val_pr_auc: 0.6827\n",
      "Epoch 20/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0505 - pr_auc: 0.8767 - val_loss: 0.0992 - val_pr_auc: 0.6831\n",
      "Epoch 21/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0495 - pr_auc: 0.8830 - val_loss: 0.1040 - val_pr_auc: 0.6704\n",
      "Epoch 22/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0478 - pr_auc: 0.8893 - val_loss: 0.1072 - val_pr_auc: 0.6607\n",
      "Epoch 23/50\n",
      "2129/2129 [==============================] - 7s 3ms/step - loss: 0.0466 - pr_auc: 0.8932 - val_loss: 0.1071 - val_pr_auc: 0.6704\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "Optimal units in first layer: {best_hps.get('units_1')}\n",
    "Optimal dropout in first layer: {best_hps.get('dropout_1')}\n",
    "Optimal units in second layer: {best_hps.get('units_2')}\n",
    "Optimal dropout in second layer: {best_hps.get('dropout_2')}\n",
    "Optimal units in third layer: {best_hps.get('units_3')}\n",
    "Optimal dropout in third layer: {best_hps.get('dropout_3')}\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6f760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3427, number of negative: 64681\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.434803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497459\n",
      "[LightGBM] [Info] Number of data points in the train set: 68108, number of used features: 6629\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050317 -> initscore=-2.937782\n",
      "[LightGBM] [Info] Start training from score -2.937782\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's average_precision: 0.271302\tvalid_0's binary_logloss: 0.183753\n",
      "[20]\tvalid_0's average_precision: 0.282293\tvalid_0's binary_logloss: 0.182261\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's average_precision: 0.281686\tvalid_0's binary_logloss: 0.182231\n",
      "\n",
      "Best Threshold for LightGBM (F2-score): 0.0983\n",
      "\n",
      "--- LightGBM Performance on Test Set ---\n",
      "[[7184  897]\n",
      " [ 139  294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      8081\n",
      "           1       0.25      0.68      0.36       433\n",
      "\n",
      "    accuracy                           0.88      8514\n",
      "   macro avg       0.61      0.78      0.65      8514\n",
      "weighted avg       0.94      0.88      0.90      8514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "neg = (y_train == 0).sum()\n",
    "pos = (y_train == 1).sum()\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "# 1. Initialize and train the LightGBM model\n",
    "# Use is_unbalanced=True to let the model handle the class imbalance.\n",
    "# Train on the original (but scaled) training data, NOT the SMOTE'd data.\n",
    "lgbm = lgb.LGBMClassifier(objective='binary',\n",
    "                          n_estimators=1000,\n",
    "                          learning_rate=0.005,\n",
    "                          random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "# Train the model\n",
    "lgbm.fit(X_train, y_train,\n",
    "         eval_set=[(X_val, y_val)],\n",
    "         eval_metric=\"average_precision\",\n",
    "         callbacks=[\n",
    "             lgb.early_stopping(stopping_rounds=10), # Added stopping_rounds for clarity\n",
    "             lgb.log_evaluation(period=10)            # This is the line that fixes the error\n",
    "         ])\n",
    "\n",
    "\n",
    "# 2. Find the optimal threshold for LightGBM on the validation set (same as you did for the NN)\n",
    "y_probs_lgbm_val = lgbm.predict_proba(X_val)[:, 1]\n",
    "prec_lgbm, rec_lgbm, thresholds_lgbm = precision_recall_curve(y_val, y_probs_lgbm_val)\n",
    "f2_scores_lgbm = (5 * prec_lgbm * rec_lgbm) / (4 * prec_lgbm + rec_lgbm + 1e-9)\n",
    "best_threshold_lgbm = thresholds_lgbm[np.argmax(f2_scores_lgbm)]\n",
    "\n",
    "print(f\"\\nBest Threshold for LightGBM (F2-score): {best_threshold_lgbm:.4f}\")\n",
    "\n",
    "# Evaluate on the test set with the optimized threshold\n",
    "y_probs_lgbm_test = lgbm.predict_proba(X_test)[:, 1]\n",
    "y_pred_lgbm_test = (y_probs_lgbm_test >= best_threshold_lgbm).astype(int)\n",
    "\n",
    "print(\"\\n--- LightGBM Performance on Test Set ---\")\n",
    "print(confusion_matrix(y_test, y_pred_lgbm_test))\n",
    "print(classification_report(y_test, y_pred_lgbm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34421098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Random Forest ---\n",
      "\n",
      "Best Threshold for Random Forest (F2-score): 0.1000\n",
      "\n",
      "--- Random Forest Performance on Test Set ---\n",
      "[[7592  489]\n",
      " [ 133  300]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      8081\n",
      "           1       0.38      0.69      0.49       433\n",
      "\n",
      "    accuracy                           0.93      8514\n",
      "   macro avg       0.68      0.82      0.73      8514\n",
      "weighted avg       0.95      0.93      0.94      8514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "\n",
    "# 1. Initialize and train the Random Forest model\n",
    "print(\"--- Training Random Forest ---\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,          # The number of trees in the forest\n",
    "    class_weight='balanced',   # Handles class imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1                  # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Train on the original (un-SMOTEd) data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 2. Find the optimal threshold on the validation set\n",
    "y_probs_rf_val = rf.predict_proba(X_val)[:, 1]\n",
    "prec_rf, rec_rf, thresholds_rf = precision_recall_curve(y_val, y_probs_rf_val)\n",
    "f2_scores_rf = (5 * prec_rf * rec_rf) / (4 * prec_rf + rec_rf + 1e-9)\n",
    "best_threshold_rf = thresholds_rf[np.argmax(f2_scores_rf)]\n",
    "\n",
    "print(f\"\\nBest Threshold for Random Forest (F2-score): {best_threshold_rf:.4f}\")\n",
    "\n",
    "# 3. Evaluate on the test set with the optimized threshold\n",
    "y_probs_rf_test = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf_test = (y_probs_rf_test >= best_threshold_rf).astype(int)\n",
    "\n",
    "print(\"\\n--- Random Forest Performance on Test Set ---\")\n",
    "print(confusion_matrix(y_test, y_pred_rf_test))\n",
    "print(classification_report(y_test, y_pred_rf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfc2bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training XGBoost ---\n",
      "\n",
      "Best Threshold for XGBoost (F2-score): 0.0949\n",
      "\n",
      "--- XGBoost Performance on Test Set ---\n",
      "[[7546  535]\n",
      " [ 102  331]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      8081\n",
      "           1       0.38      0.76      0.51       433\n",
      "\n",
      "    accuracy                           0.93      8514\n",
      "   macro avg       0.68      0.85      0.73      8514\n",
      "weighted avg       0.96      0.93      0.94      8514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1. Calculate the weight for the positive class\n",
    "# ratio of negative samples to positive samples\n",
    "scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "\n",
    "# 2. Initialize and train the XGBoost model\n",
    "print(\"\\n--- Training XGBoost ---\")\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='aucpr',\n",
    "    scale_pos_weight=scale_pos_weight, # Handles class imbalance\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model with early stopping\n",
    "xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False  # Set to True to see training progress\n",
    ")\n",
    "\n",
    "# 3. Find the optimal threshold on the validation set\n",
    "y_probs_xgb_val = xgb.predict_proba(X_val)[:, 1]\n",
    "prec_xgb, rec_xgb, thresholds_xgb = precision_recall_curve(y_val, y_probs_xgb_val)\n",
    "f2_scores_xgb = (5 * prec_xgb * rec_xgb) / (4 * prec_xgb + rec_xgb + 1e-9)\n",
    "best_threshold_xgb = thresholds_xgb[np.argmax(f2_scores_xgb)]\n",
    "\n",
    "print(f\"\\nBest Threshold for XGBoost (F2-score): {best_threshold_xgb:.4f}\")\n",
    "\n",
    "# 4. Evaluate on the test set with the optimized threshold\n",
    "y_probs_xgb_test = xgb.predict_proba(X_test)[:, 1]\n",
    "y_pred_xgb_test = (y_probs_xgb_test >= best_threshold_xgb).astype(int)\n",
    "\n",
    "print(\"\\n--- XGBoost Performance on Test Set ---\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb_test))\n",
    "print(classification_report(y_test, y_pred_xgb_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 0s 787us/step\n",
      "\\n--- Predictions for Need ID: 4618 (PRÁCTICA OBRERA: Registro de tapas de cámaras en l...) ---\n",
      "Summary: Found 1 of 1 true matches.\n",
      "----------------------------------------------------------------------\n",
      "                                              offer_name  has_match  prediction  probability\n",
      "                             Práctica Obrera Verano-2022          1           1     0.996601\n",
      "Dilab-Laboratorio Diseño en Ingeniería y Sistemas 1-2023          0           0     0.000563\n",
      "                                     Antro-Diseño 1-2023          0           0     0.000015\n",
      "----------------------------------------------------------------------\n",
      "\\n--- Predictions for Need ID: 8288 (Estudio preinversional proyecto “Espacio Mayor Chi...) ---\n",
      "Summary: Found 1 of 1 true matches.\n",
      "----------------------------------------------------------------------\n",
      "                 offer_name  has_match  prediction  probability\n",
      "Práctica Profesional 1-2025          1           1     0.939067\n",
      "----------------------------------------------------------------------\n",
      "\\n--- Predictions for Need ID: 326 (Desarrollo de estrategia de marketing para emprend...) ---\n",
      "Summary: Found 1 of 1 true matches.\n",
      "----------------------------------------------------------------------\n",
      "                                               offer_name  has_match  prediction  probability\n",
      "                       Práctica de servicio diseño 2-2017          1           1 9.649900e-01\n",
      "Iniciación Profesional a la Psicología Educacional 2-2017          0           0 1.027094e-03\n",
      "                           Evaluación de Proyectos 2-2017          0           0 8.346825e-04\n",
      "         Taller de gestión de proyectos culturales 2-2017          0           0 3.306299e-04\n",
      "     Promoción y Prevención de Salud en el Trabajo 2-2017          0           0 4.518128e-05\n",
      "                              Proyecto de título I 2-2017          0           0 2.559659e-05\n",
      "                              Proyecto de título I 2-2017          0           0 2.559659e-05\n",
      "                            Taller de ejercitación 2-2017          0           0 2.495800e-05\n",
      "                   Sustentabilidad en Construcción 1-2018          0           0 1.711949e-05\n",
      "                                         Seminario 1-2018          0           0 1.172789e-05\n",
      "                              Taller de Titulación 2-2017          0           0 1.466567e-06\n",
      "                 Análisis de Datos e Investigación 2-2017          0           0 7.761567e-07\n",
      "----------------------------------------------------------------------\n",
      "\\n--- Predictions for Need ID: 12015 (Mapeo de empresas con políticas de contratación ju...) ---\n",
      "Summary: Found 2 of 2 true matches.\n",
      "----------------------------------------------------------------------\n",
      "                               offer_name  has_match  prediction  probability\n",
      "Actividad Curricular de titulación 2-2025          1           1     0.997912\n",
      "           Práctica Social (curso) 2-2025          1           1     0.992393\n",
      "----------------------------------------------------------------------\n",
      "\\n--- Predictions for Need ID: 765 (Evaluación del área de influencia de la desinfecci...) ---\n",
      "Summary: Found 1 of 1 true matches.\n",
      "----------------------------------------------------------------------\n",
      "                 offer_name  has_match  prediction  probability\n",
      "Práctica Profesional 2-2018          1           1     0.995372\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. Get predictions from your trained neural network on the test set\n",
    "y_probs_test = model.predict(X_test_scaled)\n",
    "y_pred_test = (y_probs_test > best_threshold).astype(int)\n",
    "\n",
    "# 2. Create a results DataFrame using the original data\n",
    "# We use the index of X_test to select the correct rows from the original dataframe\n",
    "results_df = original_df.loc[X_test.index].copy()\n",
    "results_df['has_match'] = y_test\n",
    "results_df['probability'] = y_probs_test\n",
    "results_df['prediction'] = y_pred_test\n",
    "\n",
    "# 3. Select relevant columns for a clean view\n",
    "view_cols = ['need_id', 'need_name', 'offer_name', 'has_match', 'prediction', 'probability']\n",
    "final_results = results_df[view_cols]\n",
    "\n",
    "# 4. Group by need_id and display the results\n",
    "# We'll show a few examples where there was at least one true match in the test set\n",
    "needs_with_matches_in_test = final_results[final_results['has_match'] == 1]['need_id'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a20e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 0s 828us/step\n",
      "Prediction results have been prepared.\n",
      "\n",
      "You can inspect the following need_ids from the test set:\n",
      "[ 4618  8288   326 12015   765  4208   931  5552  4698   367  3493  5112\n",
      " 11388  1419  1684  5444  1906 12418 11355  3877  4116   325  3202 10531\n",
      " 12609  5056   163 14622 17955  4231   531 11558 12081  4657  2103  4822\n",
      "  1003  6867 17493 18087  3909   964  1972  1167 14919  5278  3680   607\n",
      "  1126  2762   949  2757   644   514  4325 18149   331  3326   610  4550\n",
      "  2302  3047  4151  4040  5514   932  5352  2316 16569  5189  5001  4175\n",
      "  4898 10497  1925   630  3225  1192  2525 17757  5371  5621  3169   577\n",
      "  8716   370  2432  5641  2190  5353  1127   849  4485 16404  5163  3522\n",
      " 17597  5201 12807 17692  1461  4063 10333  1747  4447  2593  5072  3824\n",
      "  3128   995  2752  4190  1797    36  2590 12840 14688  1838  3875  5354\n",
      " 12775  4604  4742  5094  3726   407  5159  5522  3408  3434  5466 17988\n",
      "  3293 17889  5095   113  3427   551  2591   467  3882 13116 16075  4658\n",
      "   994  7165  4563  5745  5103  3072  5297  2126  1278  3531  4010  3021\n",
      " 10860   888   756  5476 10861  2201   476 12708  1464  5560  2669  1466\n",
      "  4085  1527  1963 13104   712  1131 13137  1846  5460  4425   613  4181\n",
      "  4298  1344  1352  2441  5156  2855 15746  4295  1019   807  2576    63\n",
      "  4897   198  4923  7799  6109   429  5061 15183  3510   393  1426  5147\n",
      "  1518  7798 17132  2111  4160 11563  4896  1222  5171 12114    97  4318\n",
      "  5333  2980   363  1483  3327  4571  6604 15977  1017  4599  3285  1536\n",
      " 16076  4824  3428  8055   179  5214   759  9640  1336  4745  4133 17035\n",
      "  4179 11916  3579    39  1084  1347 12183  1189  3871  5627  3903  4029\n",
      "  4947  1546  4935 14523 18153  1604   505  2186  1044   119 14590   468\n",
      "   604  2440   123  2030  1080  3120  5064   431  4052  2944  1290   108\n",
      "  5532 12180  3199  3608  4365 14856  5252  2267  7725  7528  2422  1506\n",
      " 16470   417   295   816  1180  8352  4207   667  1568  4878   794  4905\n",
      "  3691  1364  1921  1717  4323  1924  1830  4778 17131  4051  4100  1918\n",
      "  3339   871  2769  7800  2683  1544 17791   222  1122  3468   293  5059\n",
      "  4642  1348  5063   522 15084  4317 12741  3688   958  4648  1346  4054\n",
      "  4927  5114   998  3193   204  1049  8319 17790  1103  4220  4546   879\n",
      "  5236  9705 11555 10301  2521  3054  9015  2979  3357   782   956  1115\n",
      "  1908  1503  1064  1526  1909  5338   249  5192    72 14028  1476 16041\n",
      "  3226   558  2597   474  5366  2429  2885   779  3532  5432  2448  5335\n",
      "  4888   488  1651  8291  1288 11125  3516   127  4975  4293 14556   466\n",
      "   125  5506  4738  8847  1010  4877   572   333  5643  2902  4655  3826\n",
      "  5433   418  1181  4864   298]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Preparation: Create the Results DataFrame (Run this once) ---\n",
    "# This example uses your champion Neural Network model.\n",
    "# You can swap 'model' with 'xgb' or another trained model to see its predictions.\n",
    "\n",
    "# Get predictions on the test set using your best model and threshold\n",
    "y_probs_test = model.predict(X_test_scaled)\n",
    "y_pred_test = (y_probs_test > best_threshold).astype(int) # Use the threshold you found for the NN\n",
    "\n",
    "# Create a DataFrame with predictions linked back to the original data\n",
    "results_df = merged.loc[X_test.index].copy()\n",
    "results_df['has_match'] = y_test\n",
    "results_df['probability'] = y_probs_test\n",
    "results_df['prediction'] = y_pred_test\n",
    "\n",
    "# Select the most relevant columns for a clean view\n",
    "view_cols = ['need_id', 'need_name', 'offer_name', 'name', 'has_match', 'prediction', 'probability']\n",
    "final_results = results_df[view_cols]\n",
    "\n",
    "print(\"Prediction results have been prepared.\")\n",
    "\n",
    "\n",
    "# --- 2. The Interactive Function ---\n",
    "def display_need_predictions(need_id, results_df):\n",
    "    \"\"\"\n",
    "    Displays a summary of model predictions for a specific need_id,\n",
    "    sorted by probability.\n",
    "    \"\"\"\n",
    "    # Filter the results for the specified need_id\n",
    "    group = results_df[results_df['need_id'] == need_id]\n",
    "\n",
    "    # Check if the need_id exists in the test set results\n",
    "    if group.empty:\n",
    "        print(f\"Sorry, Need ID: {need_id} was not found in the test set.\")\n",
    "        return\n",
    "\n",
    "    # Sort the results by the model's predicted probability\n",
    "    group = group.sort_values('probability', ascending=False)\n",
    "    \n",
    "    need_name = group['need_name'].iloc[0]\n",
    "    \n",
    "    print(f\"\\n--- Predictions for Need ID: {need_id} ({need_name[:50]}...) ---\")\n",
    "    \n",
    "    # Calculate summary stats for this need\n",
    "    true_matches = group['has_match'].sum()\n",
    "    predicted_matches = group['prediction'].sum()\n",
    "    correctly_predicted = group[(group['has_match'] == 1) & (group['prediction'] == 1)].shape[0]\n",
    "\n",
    "    print(f\"Summary: The model found {correctly_predicted} of the {true_matches} true matches for this need.\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Print the ranked list of potential offers for this need\n",
    "    print(group[['offer_name', 'name', 'has_match', 'prediction', 'probability']].to_string(index=False))\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# --- 3. How to Use the Function ---\n",
    "\n",
    "# First, find some interesting need_ids to inspect from your test set\n",
    "# (e.g., ones that we know have at least one true match)\n",
    "needs_with_matches_in_test = final_results[final_results['has_match'] == 1]['need_id'].unique()\n",
    "print(\"\\nYou can inspect the following need_ids from the test set:\")\n",
    "print(needs_with_matches_in_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c65c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predictions for Need ID: 1181 (Estudio sobre aguas de rechazo en plantas de ósmos...) ---\n",
      "Summary: The model found 1 of the 1 true matches for this need.\n",
      "--------------------------------------------------------------------------------\n",
      "                                    offer_name                       name  has_match  prediction  probability\n",
      "                    Seminario de Título 1-2019             Agro_Prácticas          1           1     0.735178\n",
      "           Taller de Titulacion II Verano-2019       Sociología_Prácticas          0           0     0.021890\n",
      "               Taller de Integración IV 2-2018         Psicología_General          0           0     0.001877\n",
      "Actividad Curricular de titulación Verano-2019 Ciencia Política_Prácticas          0           0     0.001512\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Predictions for Need ID: 298 (Práctica de diseño para apoyar emprendimientos sus...) ---\n",
      "Summary: The model found 1 of the 1 true matches for this need.\n",
      "--------------------------------------------------------------------------------\n",
      "                                          offer_name                       name  has_match  prediction  probability\n",
      "                  Práctica de servicio diseño 2-2017           Diseño_Prácticas          1           1     0.999330\n",
      "                    Práctica Profesional Verano-2017        Comercial_Prácticas          0           0     0.021858\n",
      "                           Taller: Mercado II 2-2017                Cluster 185          0           0     0.002239\n",
      "                    Práctica Ciencia Política 2-2017 Ciencia Política_Prácticas          0           0     0.002178\n",
      "                         Práctica Profesional 2-2017       Ingeniería_Prácticas          0           0     0.001204\n",
      "          Técnicas de Representación Espacial 2-2017                Cluster 186          0           0     0.000020\n",
      "       Enfermería en salud de la comunidad II 2-2017     Enfermería_Comunitaria          0           0     0.000012\n",
      "               Práctica en Psicología Laboral 1-2018  Psicología_Organizacional          0           0     0.000011\n",
      "Promoción y Prevención de Salud en el Trabajo 2-2017           Psicología_Salud          0           0     0.000004\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, call the function with a need_id of your choice\n",
    "# Example:\n",
    "display_need_predictions(1181, final_results)\n",
    "display_need_predictions(298, final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f50c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for rows that are False Negatives (True Match = 1, Predicted = 0)\n",
    "missed_matches_df = final_results[(final_results['has_match'] == 1) & (final_results['prediction'] == 0)]\n",
    "\n",
    "# Get a unique list of the need_ids from that filtered DataFrame\n",
    "needs_with_missed_matches = missed_matches_df['need_id'].unique()\n",
    "\n",
    "print(\"The following need_ids had at least one true match that the model failed to predict:\")\n",
    "print(needs_with_missed_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd06ac9-37ff-4d38-aab5-3a23f96d234f",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "puentes_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
