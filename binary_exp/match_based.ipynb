{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73aa66a-d1f3-4a31-99d1-224485f66339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score, precision_score, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import keras_tuner as kt\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d016ef8-e96f-4e2c-a7eb-294142c1862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('pairs_with_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f76cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a951a2f8-9554-4c0d-9534-292289d82b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "need_emb_cols = [f'need_emb_{i}' for i in range(3072)]\n",
    "res_emb_cols = [f'res_emb_{i}' for i in range(3072)]\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "need_embs = df[need_emb_cols].to_numpy()\n",
    "res_embs = df[res_emb_cols].to_numpy()\n",
    "\n",
    "# Compute cosine similarity row-wise\n",
    "cos_sim = np.einsum('ij,ij->i', need_embs, res_embs) / (\n",
    "    np.linalg.norm(need_embs, axis=1) * np.linalg.norm(res_embs, axis=1) + 1e-9\n",
    ")\n",
    "\n",
    "df['cosine_similarity'] = cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7063d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create richer features\n",
    "df['l2_distance'] = np.linalg.norm(need_embs - res_embs, axis=1)\n",
    "df['dot_product'] = np.einsum('ij,ij->i', need_embs, res_embs)\n",
    "\n",
    "# Optional: elementwise interaction features\n",
    "interaction = need_embs * res_embs\n",
    "interaction_mean = interaction.mean(axis=1)\n",
    "df['interaction_mean'] = interaction_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8ae35c-7b8b-4587-b428-fd939aa6fea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academic_resource_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>Cluster 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321</td>\n",
       "      <td>Sociología_Prácticas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>640</td>\n",
       "      <td>Cluster 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>225</td>\n",
       "      <td>Cluster 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>253</td>\n",
       "      <td>Cluster 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   academic_resource_id                  name\n",
       "0                   391             Cluster 1\n",
       "1                   321  Sociología_Prácticas\n",
       "2                   640             Cluster 2\n",
       "3                   225             Cluster 3\n",
       "4                   253             Cluster 4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = pd.read_csv('clusters.csv')\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5f12e7-a742-404e-91b9-f76a94cb05d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>need_id</th>\n",
       "      <th>need_name</th>\n",
       "      <th>need_description</th>\n",
       "      <th>need_expiration_date</th>\n",
       "      <th>need_created_at</th>\n",
       "      <th>need_internship</th>\n",
       "      <th>offer_name</th>\n",
       "      <th>offer_description</th>\n",
       "      <th>offer_semester</th>\n",
       "      <th>offer_company_year</th>\n",
       "      <th>...</th>\n",
       "      <th>res_emb_3067</th>\n",
       "      <th>res_emb_3068</th>\n",
       "      <th>res_emb_3069</th>\n",
       "      <th>res_emb_3070</th>\n",
       "      <th>res_emb_3071</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>l2_distance</th>\n",
       "      <th>dot_product</th>\n",
       "      <th>interaction_mean</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1456</td>\n",
       "      <td>Investigación sobre los factores que inciden e...</td>\n",
       "      <td>De acuerdo a la temáticas sociales y en especi...</td>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>2019-02-04 14:56:21.388586</td>\n",
       "      <td>True</td>\n",
       "      <td>Pasantía de College 1-2019</td>\n",
       "      <td>Pasantía cocurricular de al menos 160 horas, d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048212</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>-0.013416</td>\n",
       "      <td>-0.028706</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>0.411339</td>\n",
       "      <td>1.085045</td>\n",
       "      <td>0.411339</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>College CCNN_Pasantías</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5168</td>\n",
       "      <td>Apoyo y elaboración de plan de marketing para ...</td>\n",
       "      <td>La Fábrica de Renca es una entidad privada sin...</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>2023-09-20 20:05:59.124840</td>\n",
       "      <td>True</td>\n",
       "      <td>Práctica Profesional 2-2023</td>\n",
       "      <td>Práctica profesional obligatoria de 320 horas ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039514</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.006662</td>\n",
       "      <td>-0.018958</td>\n",
       "      <td>-0.012061</td>\n",
       "      <td>0.486173</td>\n",
       "      <td>1.013733</td>\n",
       "      <td>0.486173</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>Comercial_Prácticas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5152</td>\n",
       "      <td>Taller de Intervención para Programa de Calle ...</td>\n",
       "      <td>El curso taller de intervención tiene como pro...</td>\n",
       "      <td>2024-03-06</td>\n",
       "      <td>2023-09-06 19:51:21.818464</td>\n",
       "      <td>True</td>\n",
       "      <td>Taller de Intervención 2-2023</td>\n",
       "      <td>Taller de intervención dirigido a estudiantes ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049481</td>\n",
       "      <td>-0.002994</td>\n",
       "      <td>-0.004206</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.782764</td>\n",
       "      <td>0.659146</td>\n",
       "      <td>0.782764</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>Trabajo Social_Práctica Inicial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3993</td>\n",
       "      <td>Diagnóstico de la población migrante en Renca ...</td>\n",
       "      <td>Desde el departamento de inclusión de la munic...</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>2022-03-22 13:54:44.014323</td>\n",
       "      <td>True</td>\n",
       "      <td>Pasantía Verano-2021</td>\n",
       "      <td>Pasantía cocurricular de al menos 160 horas, d...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045297</td>\n",
       "      <td>-0.006526</td>\n",
       "      <td>-0.019708</td>\n",
       "      <td>-0.012770</td>\n",
       "      <td>-0.005960</td>\n",
       "      <td>0.520189</td>\n",
       "      <td>0.979603</td>\n",
       "      <td>0.520189</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>Sociología_Prácticas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1907</td>\n",
       "      <td>Práctica Inicial Trabajo Social (II) - Unidad ...</td>\n",
       "      <td>Dentro de los objetivos de la Unidad Técnica d...</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>2019-08-19 14:00:49.570249</td>\n",
       "      <td>True</td>\n",
       "      <td>Práctica Inicial II 2-2019</td>\n",
       "      <td>Segunda parte del taller de intervención dirig...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046884</td>\n",
       "      <td>-0.001429</td>\n",
       "      <td>-0.001713</td>\n",
       "      <td>-0.005516</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0.396248</td>\n",
       "      <td>1.098865</td>\n",
       "      <td>0.396248</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>Trabajo Social_Práctica Inicial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   need_id                                          need_name  \\\n",
       "0     1456  Investigación sobre los factores que inciden e...   \n",
       "1     5168  Apoyo y elaboración de plan de marketing para ...   \n",
       "2     5152  Taller de Intervención para Programa de Calle ...   \n",
       "3     3993  Diagnóstico de la población migrante en Renca ...   \n",
       "4     1907  Práctica Inicial Trabajo Social (II) - Unidad ...   \n",
       "\n",
       "                                    need_description need_expiration_date  \\\n",
       "0  De acuerdo a la temáticas sociales y en especi...           2019-08-04   \n",
       "1  La Fábrica de Renca es una entidad privada sin...           2024-03-20   \n",
       "2  El curso taller de intervención tiene como pro...           2024-03-06   \n",
       "3  Desde el departamento de inclusión de la munic...           2022-09-22   \n",
       "4  Dentro de los objetivos de la Unidad Técnica d...           2020-02-19   \n",
       "\n",
       "              need_created_at  need_internship                     offer_name  \\\n",
       "0  2019-02-04 14:56:21.388586             True     Pasantía de College 1-2019   \n",
       "1  2023-09-20 20:05:59.124840             True    Práctica Profesional 2-2023   \n",
       "2  2023-09-06 19:51:21.818464             True  Taller de Intervención 2-2023   \n",
       "3  2022-03-22 13:54:44.014323             True           Pasantía Verano-2021   \n",
       "4  2019-08-19 14:00:49.570249             True     Práctica Inicial II 2-2019   \n",
       "\n",
       "                                   offer_description  offer_semester  \\\n",
       "0  Pasantía cocurricular de al menos 160 horas, d...             0.0   \n",
       "1  Práctica profesional obligatoria de 320 horas ...             1.0   \n",
       "2  Taller de intervención dirigido a estudiantes ...             1.0   \n",
       "3  Pasantía cocurricular de al menos 160 horas, d...             2.0   \n",
       "4  Segunda parte del taller de intervención dirig...             1.0   \n",
       "\n",
       "   offer_company_year  ... res_emb_3067  res_emb_3068 res_emb_3069  \\\n",
       "0                2019  ...     0.048212      0.003851    -0.013416   \n",
       "1                2023  ...     0.039514     -0.000184    -0.006662   \n",
       "2                2023  ...     0.049481     -0.002994    -0.004206   \n",
       "3                2021  ...     0.045297     -0.006526    -0.019708   \n",
       "4                2019  ...     0.046884     -0.001429    -0.001713   \n",
       "\n",
       "   res_emb_3070 res_emb_3071 cosine_similarity  l2_distance  dot_product  \\\n",
       "0     -0.028706    -0.004475          0.411339     1.085045     0.411339   \n",
       "1     -0.018958    -0.012061          0.486173     1.013733     0.486173   \n",
       "2     -0.003688     0.003104          0.782764     0.659146     0.782764   \n",
       "3     -0.012770    -0.005960          0.520189     0.979603     0.520189   \n",
       "4     -0.005516     0.009988          0.396248     1.098865     0.396248   \n",
       "\n",
       "   interaction_mean                             name  \n",
       "0          0.000134           College CCNN_Pasantías  \n",
       "1          0.000158              Comercial_Prácticas  \n",
       "2          0.000255  Trabajo Social_Práctica Inicial  \n",
       "3          0.000169             Sociología_Prácticas  \n",
       "4          0.000129  Trabajo Social_Práctica Inicial  \n",
       "\n",
       "[5 rows x 6168 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = df.merge(clusters, on=\"academic_resource_id\", how=\"left\")\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62158b9e-58a4-4a61-a2e2-9fb823162950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged\n",
    "df = df.drop(columns=['academic_resource_description','need_id','need_name','need_description','need_expiration_date','need_created_at','offer_description','offer_name','offer_semester','offer_company_year','offer_expiration_date','offer_academic_resource_id','offer_created_at','academic_resource_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b86583-d26b-4d35-8a1b-b8a42cf921da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"need_internship\"] = df[\"need_internship\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c727b359-b756-4075-aeaa-7e93f9651eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 6154)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4739867-24aa-436e-9c70-d8a3e90a9650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>need_internship</th>\n",
       "      <th>academic_resource_id</th>\n",
       "      <th>academic_resource_level</th>\n",
       "      <th>academic_resource_type_id</th>\n",
       "      <th>has_match</th>\n",
       "      <th>need_emb_0</th>\n",
       "      <th>need_emb_1</th>\n",
       "      <th>need_emb_2</th>\n",
       "      <th>need_emb_3</th>\n",
       "      <th>need_emb_4</th>\n",
       "      <th>...</th>\n",
       "      <th>res_emb_3067</th>\n",
       "      <th>res_emb_3068</th>\n",
       "      <th>res_emb_3069</th>\n",
       "      <th>res_emb_3070</th>\n",
       "      <th>res_emb_3071</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>l2_distance</th>\n",
       "      <th>dot_product</th>\n",
       "      <th>interaction_mean</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011038</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>-0.007517</td>\n",
       "      <td>-0.016986</td>\n",
       "      <td>0.014604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048212</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>-0.013416</td>\n",
       "      <td>-0.028706</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>0.411339</td>\n",
       "      <td>1.085045</td>\n",
       "      <td>0.411339</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>College CCNN_Pasantías</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.008638</td>\n",
       "      <td>0.036582</td>\n",
       "      <td>-0.013364</td>\n",
       "      <td>-0.018138</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039514</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.006662</td>\n",
       "      <td>-0.018958</td>\n",
       "      <td>-0.012061</td>\n",
       "      <td>0.486173</td>\n",
       "      <td>1.013733</td>\n",
       "      <td>0.486173</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>Comercial_Prácticas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>582</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.034407</td>\n",
       "      <td>-0.001854</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.020503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049481</td>\n",
       "      <td>-0.002994</td>\n",
       "      <td>-0.004206</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.782764</td>\n",
       "      <td>0.659146</td>\n",
       "      <td>0.782764</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>Trabajo Social_Práctica Inicial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007967</td>\n",
       "      <td>0.022626</td>\n",
       "      <td>-0.013080</td>\n",
       "      <td>-0.032534</td>\n",
       "      <td>0.038485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045297</td>\n",
       "      <td>-0.006526</td>\n",
       "      <td>-0.019708</td>\n",
       "      <td>-0.012770</td>\n",
       "      <td>-0.005960</td>\n",
       "      <td>0.520189</td>\n",
       "      <td>0.979603</td>\n",
       "      <td>0.520189</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>Sociología_Prácticas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>286</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>-0.005712</td>\n",
       "      <td>-0.003436</td>\n",
       "      <td>-0.047204</td>\n",
       "      <td>0.015465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046884</td>\n",
       "      <td>-0.001429</td>\n",
       "      <td>-0.001713</td>\n",
       "      <td>-0.005516</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0.396248</td>\n",
       "      <td>1.098865</td>\n",
       "      <td>0.396248</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>Trabajo Social_Práctica Inicial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   need_internship  academic_resource_id  academic_resource_level  \\\n",
       "0                1                   250                        1   \n",
       "1                1                   205                        2   \n",
       "2                1                   582                        1   \n",
       "3                1                   330                        2   \n",
       "4                1                   286                        1   \n",
       "\n",
       "   academic_resource_type_id  has_match  need_emb_0  need_emb_1  need_emb_2  \\\n",
       "0                         24          1   -0.011038    0.009111   -0.007517   \n",
       "1                         21          1   -0.008638    0.036582   -0.013364   \n",
       "2                         21          1    0.010936    0.034407   -0.001854   \n",
       "3                         24          1   -0.007967    0.022626   -0.013080   \n",
       "4                         21          1    0.002075   -0.005712   -0.003436   \n",
       "\n",
       "   need_emb_3  need_emb_4  ...  res_emb_3067  res_emb_3068  res_emb_3069  \\\n",
       "0   -0.016986    0.014604  ...      0.048212      0.003851     -0.013416   \n",
       "1   -0.018138    0.011307  ...      0.039514     -0.000184     -0.006662   \n",
       "2    0.008706    0.020503  ...      0.049481     -0.002994     -0.004206   \n",
       "3   -0.032534    0.038485  ...      0.045297     -0.006526     -0.019708   \n",
       "4   -0.047204    0.015465  ...      0.046884     -0.001429     -0.001713   \n",
       "\n",
       "   res_emb_3070  res_emb_3071  cosine_similarity  l2_distance  dot_product  \\\n",
       "0     -0.028706     -0.004475           0.411339     1.085045     0.411339   \n",
       "1     -0.018958     -0.012061           0.486173     1.013733     0.486173   \n",
       "2     -0.003688      0.003104           0.782764     0.659146     0.782764   \n",
       "3     -0.012770     -0.005960           0.520189     0.979603     0.520189   \n",
       "4     -0.005516      0.009988           0.396248     1.098865     0.396248   \n",
       "\n",
       "   interaction_mean                             name  \n",
       "0          0.000134           College CCNN_Pasantías  \n",
       "1          0.000158              Comercial_Prácticas  \n",
       "2          0.000255  Trabajo Social_Práctica Inicial  \n",
       "3          0.000169             Sociología_Prácticas  \n",
       "4          0.000129  Trabajo Social_Práctica Inicial  \n",
       "\n",
       "[5 rows x 6154 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc6e4bad-5e12-4565-9a97-c924034462ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy categories columns\n",
    "categorical_cols = ['academic_resource_id','academic_resource_level','academic_resource_type_id','name']\n",
    "df_dummies = pd.get_dummies(df, columns=categorical_cols)\n",
    "df_dummies\n",
    "df = df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50e91f00-1ffd-4808-b84d-e09e6c3a9cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['has_match'])\n",
    "y = df['has_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df9ea7d3-e3e5-4138-8c3e-d6c3647db04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Split the data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6843193-1d15-4317-86eb-d9aeb3a92c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# Use the same scaler to transform the validation and test sets\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "967aaaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original training data: (68108, 6664)\n",
      "Shape of resampled training data: (129362, 6664)\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Shape of original training data:\", X_train_scaled.shape)\n",
    "print(\"Shape of resampled training data:\", X_train_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e14fbd57-ec29-4c66-9716-c11e67b6ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_pr_auc\", mode=\"max\", patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_pr_auc\", mode=\"max\", factor=0.5, patience=2, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "955b70a0-3b87-45b5-a885-29512d64d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Build the model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_resampled.shape[1],)),\n",
    "\n",
    "    Dense(96, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(1, activation='sigmoid')  # clasificación binaria\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c7f18c-f225-4821-8bf8-a854021093de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 96)                639840    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 96)                384       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 96)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                6208      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 646753 (2.47 MB)\n",
      "Trainable params: 646433 (2.47 MB)\n",
      "Non-trainable params: 320 (1.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pr_auc = AUC(curve=\"PR\", name=\"pr_auc\")\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[Precision(name=\"precision\"), Recall(name=\"recall\"), AUC(name=\"auc\"), pr_auc],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "debbd185-525a-4d05-9bde-202bff7229be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4043/4043 [==============================] - 11s 2ms/step - loss: 0.2825 - precision: 0.8663 - recall: 0.9002 - auc: 0.9501 - pr_auc: 0.9435 - val_loss: 0.1930 - val_precision: 0.3508 - val_recall: 0.8166 - val_auc: 0.9492 - val_pr_auc: 0.5964 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "4043/4043 [==============================] - 7s 2ms/step - loss: 0.1801 - precision: 0.9199 - recall: 0.9462 - auc: 0.9782 - pr_auc: 0.9731 - val_loss: 0.1515 - val_precision: 0.4229 - val_recall: 0.7775 - val_auc: 0.9544 - val_pr_auc: 0.6395 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.1492 - precision: 0.9344 - recall: 0.9568 - auc: 0.9845 - pr_auc: 0.9810 - val_loss: 0.1541 - val_precision: 0.4282 - val_recall: 0.8093 - val_auc: 0.9575 - val_pr_auc: 0.6645 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "4043/4043 [==============================] - 7s 2ms/step - loss: 0.1312 - precision: 0.9420 - recall: 0.9633 - auc: 0.9875 - pr_auc: 0.9841 - val_loss: 0.1446 - val_precision: 0.4659 - val_recall: 0.7848 - val_auc: 0.9511 - val_pr_auc: 0.6477 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "4040/4043 [============================>.] - ETA: 0s - loss: 0.1181 - precision: 0.9481 - recall: 0.9684 - auc: 0.9895 - pr_auc: 0.9865\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4043/4043 [==============================] - 7s 2ms/step - loss: 0.1181 - precision: 0.9482 - recall: 0.9684 - auc: 0.9895 - pr_auc: 0.9864 - val_loss: 0.1431 - val_precision: 0.4815 - val_recall: 0.7946 - val_auc: 0.9532 - val_pr_auc: 0.6526 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "4043/4043 [==============================] - 7s 2ms/step - loss: 0.0975 - precision: 0.9583 - recall: 0.9743 - auc: 0.9925 - pr_auc: 0.9902 - val_loss: 0.1326 - val_precision: 0.5132 - val_recall: 0.7604 - val_auc: 0.9553 - val_pr_auc: 0.6622 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0879 - precision: 0.9624 - recall: 0.9774 - auc: 0.9936 - pr_auc: 0.9912 - val_loss: 0.1272 - val_precision: 0.5371 - val_recall: 0.7433 - val_auc: 0.9489 - val_pr_auc: 0.6778 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0834 - precision: 0.9653 - recall: 0.9788 - auc: 0.9941 - pr_auc: 0.9920 - val_loss: 0.1199 - val_precision: 0.5588 - val_recall: 0.7090 - val_auc: 0.9461 - val_pr_auc: 0.6863 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0788 - precision: 0.9670 - recall: 0.9794 - auc: 0.9947 - pr_auc: 0.9927 - val_loss: 0.1275 - val_precision: 0.5554 - val_recall: 0.7359 - val_auc: 0.9501 - val_pr_auc: 0.6645 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "4031/4043 [============================>.] - ETA: 0s - loss: 0.0764 - precision: 0.9689 - recall: 0.9803 - auc: 0.9949 - pr_auc: 0.9930\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4043/4043 [==============================] - 8s 2ms/step - loss: 0.0765 - precision: 0.9689 - recall: 0.9803 - auc: 0.9949 - pr_auc: 0.9930 - val_loss: 0.1233 - val_precision: 0.5645 - val_recall: 0.7066 - val_auc: 0.9467 - val_pr_auc: 0.6666 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "4043/4043 [==============================] - 7s 2ms/step - loss: 0.0669 - precision: 0.9733 - recall: 0.9841 - auc: 0.9956 - pr_auc: 0.9936 - val_loss: 0.1205 - val_precision: 0.6004 - val_recall: 0.6944 - val_auc: 0.9470 - val_pr_auc: 0.6670 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "4021/4043 [============================>.] - ETA: 0s - loss: 0.0630 - precision: 0.9745 - recall: 0.9849 - auc: 0.9961 - pr_auc: 0.9944\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4043/4043 [==============================] - 9s 2ms/step - loss: 0.0629 - precision: 0.9746 - recall: 0.9849 - auc: 0.9961 - pr_auc: 0.9943 - val_loss: 0.1213 - val_precision: 0.5912 - val_recall: 0.6895 - val_auc: 0.9450 - val_pr_auc: 0.6654 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "4043/4043 [==============================] - 9s 2ms/step - loss: 0.0572 - precision: 0.9770 - recall: 0.9859 - auc: 0.9968 - pr_auc: 0.9953 - val_loss: 0.1227 - val_precision: 0.6030 - val_recall: 0.6797 - val_auc: 0.9415 - val_pr_auc: 0.6571 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "# 8. Train the model\n",
    "history = model.fit(\n",
    "    X_train_resampled, y_train_resampled,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    # class_weight=class_weight_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "069dc5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c25ed5c-7800-416b-9c5f-a179f5c8e6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 0s 687us/step - loss: 0.0972 - pr_auc: 0.7047\n",
      "[0.09717106819152832, 0.7047492265701294]\n"
     ]
    }
   ],
   "source": [
    "# 9. Evaluate the model\n",
    "metrics = model.evaluate(X_test_scaled, y_test)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38ce16a5-dd84-4ce4-9279-e1e4f2452834",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'precision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Precision\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Precision\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_precision\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Precision\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Recall\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'precision'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10. Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Precision\n",
    "plt.plot(history.history['precision'], label='Train Precision')\n",
    "plt.plot(history.history['val_precision'], label='Val Precision')\n",
    "\n",
    "# Recall\n",
    "plt.plot(history.history['recall'], label='Train Recall')\n",
    "plt.plot(history.history['val_recall'], label='Val Recall')\n",
    "\n",
    "# PR-AUC\n",
    "plt.plot(history.history['pr_auc'], label='Train PR-AUC')\n",
    "plt.plot(history.history['val_pr_auc'], label='Val PR-AUC')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Training History (Precision, Recall, PR-AUC)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2673525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 0s 601us/step\n",
      "Best threshold for F2: 0.209748\n",
      "Precision: 0.6015625 Recall: 0.7530562347188264 F2: 0.7169459960486737\n"
     ]
    }
   ],
   "source": [
    "y_probs = model.predict(X_val_scaled)\n",
    "prec, rec, thresholds = precision_recall_curve(y_val, y_probs)\n",
    "f2_scores = (5 * prec * rec) / (4 * prec + rec + 1e-9)\n",
    "best_idx = np.argmax(f2_scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "print(\"Best threshold for F2:\", best_threshold)\n",
    "print(\"Precision:\", prec[best_idx], \"Recall:\", rec[best_idx], \"F2:\", f2_scores[best_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3b40b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.00, Precision: 0.05, Recall: 1.00, PR AUC: 0.70\n",
      "Threshold: 0.01, Precision: 0.28, Recall: 0.89, PR AUC: 0.70\n",
      "Threshold: 0.02, Precision: 0.33, Recall: 0.86, PR AUC: 0.70\n",
      "Threshold: 0.03, Precision: 0.37, Recall: 0.85, PR AUC: 0.70\n",
      "Threshold: 0.04, Precision: 0.39, Recall: 0.84, PR AUC: 0.70\n",
      "Threshold: 0.05, Precision: 0.41, Recall: 0.82, PR AUC: 0.70\n",
      "Threshold: 0.06, Precision: 0.42, Recall: 0.81, PR AUC: 0.70\n",
      "Threshold: 0.07, Precision: 0.44, Recall: 0.80, PR AUC: 0.70\n",
      "Threshold: 0.08, Precision: 0.46, Recall: 0.79, PR AUC: 0.70\n",
      "Threshold: 0.09, Precision: 0.47, Recall: 0.79, PR AUC: 0.70\n",
      "Threshold: 0.10, Precision: 0.48, Recall: 0.79, PR AUC: 0.70\n",
      "Threshold: 0.11, Precision: 0.50, Recall: 0.79, PR AUC: 0.70\n",
      "Threshold: 0.12, Precision: 0.51, Recall: 0.78, PR AUC: 0.70\n",
      "Threshold: 0.13, Precision: 0.52, Recall: 0.77, PR AUC: 0.70\n",
      "Threshold: 0.14, Precision: 0.53, Recall: 0.77, PR AUC: 0.70\n",
      "Threshold: 0.15, Precision: 0.54, Recall: 0.76, PR AUC: 0.70\n",
      "Threshold: 0.16, Precision: 0.55, Recall: 0.76, PR AUC: 0.70\n",
      "Threshold: 0.17, Precision: 0.56, Recall: 0.76, PR AUC: 0.70\n",
      "Threshold: 0.18, Precision: 0.57, Recall: 0.76, PR AUC: 0.70\n",
      "Threshold: 0.19, Precision: 0.58, Recall: 0.75, PR AUC: 0.70\n",
      "Threshold: 0.20, Precision: 0.59, Recall: 0.75, PR AUC: 0.70\n",
      "Threshold: 0.21, Precision: 0.60, Recall: 0.75, PR AUC: 0.70\n",
      "Threshold: 0.22, Precision: 0.61, Recall: 0.74, PR AUC: 0.70\n",
      "Threshold: 0.23, Precision: 0.62, Recall: 0.74, PR AUC: 0.70\n",
      "Threshold: 0.24, Precision: 0.63, Recall: 0.73, PR AUC: 0.70\n",
      "Threshold: 0.25, Precision: 0.63, Recall: 0.72, PR AUC: 0.70\n",
      "Threshold: 0.26, Precision: 0.64, Recall: 0.72, PR AUC: 0.70\n",
      "Threshold: 0.27, Precision: 0.64, Recall: 0.72, PR AUC: 0.70\n",
      "Threshold: 0.28, Precision: 0.65, Recall: 0.71, PR AUC: 0.70\n",
      "Threshold: 0.29, Precision: 0.66, Recall: 0.71, PR AUC: 0.70\n",
      "Threshold: 0.30, Precision: 0.66, Recall: 0.71, PR AUC: 0.70\n",
      "Threshold: 0.31, Precision: 0.66, Recall: 0.70, PR AUC: 0.70\n",
      "Threshold: 0.32, Precision: 0.66, Recall: 0.69, PR AUC: 0.70\n",
      "Threshold: 0.33, Precision: 0.67, Recall: 0.68, PR AUC: 0.70\n",
      "Threshold: 0.34, Precision: 0.67, Recall: 0.68, PR AUC: 0.70\n",
      "Threshold: 0.35, Precision: 0.67, Recall: 0.67, PR AUC: 0.70\n",
      "Threshold: 0.36, Precision: 0.67, Recall: 0.67, PR AUC: 0.70\n",
      "Threshold: 0.37, Precision: 0.68, Recall: 0.67, PR AUC: 0.70\n",
      "Threshold: 0.38, Precision: 0.68, Recall: 0.66, PR AUC: 0.70\n",
      "Threshold: 0.39, Precision: 0.68, Recall: 0.65, PR AUC: 0.70\n",
      "Threshold: 0.40, Precision: 0.69, Recall: 0.64, PR AUC: 0.70\n",
      "Threshold: 0.41, Precision: 0.69, Recall: 0.63, PR AUC: 0.70\n",
      "Threshold: 0.42, Precision: 0.70, Recall: 0.62, PR AUC: 0.70\n",
      "Threshold: 0.43, Precision: 0.69, Recall: 0.62, PR AUC: 0.70\n",
      "Threshold: 0.44, Precision: 0.70, Recall: 0.61, PR AUC: 0.70\n",
      "Threshold: 0.45, Precision: 0.70, Recall: 0.61, PR AUC: 0.70\n",
      "Threshold: 0.46, Precision: 0.70, Recall: 0.61, PR AUC: 0.70\n",
      "Threshold: 0.47, Precision: 0.71, Recall: 0.61, PR AUC: 0.70\n",
      "Threshold: 0.48, Precision: 0.71, Recall: 0.60, PR AUC: 0.70\n",
      "Threshold: 0.49, Precision: 0.72, Recall: 0.60, PR AUC: 0.70\n",
      "Threshold: 0.50, Precision: 0.73, Recall: 0.60, PR AUC: 0.70\n",
      "Threshold: 0.51, Precision: 0.73, Recall: 0.60, PR AUC: 0.70\n",
      "Threshold: 0.52, Precision: 0.73, Recall: 0.60, PR AUC: 0.70\n",
      "Threshold: 0.53, Precision: 0.73, Recall: 0.59, PR AUC: 0.70\n",
      "Threshold: 0.54, Precision: 0.74, Recall: 0.59, PR AUC: 0.70\n",
      "Threshold: 0.55, Precision: 0.75, Recall: 0.58, PR AUC: 0.70\n",
      "Threshold: 0.56, Precision: 0.75, Recall: 0.58, PR AUC: 0.70\n",
      "Threshold: 0.57, Precision: 0.76, Recall: 0.58, PR AUC: 0.70\n",
      "Threshold: 0.58, Precision: 0.77, Recall: 0.57, PR AUC: 0.70\n",
      "Threshold: 0.59, Precision: 0.76, Recall: 0.56, PR AUC: 0.70\n",
      "Threshold: 0.60, Precision: 0.77, Recall: 0.56, PR AUC: 0.70\n",
      "Threshold: 0.61, Precision: 0.78, Recall: 0.55, PR AUC: 0.70\n",
      "Threshold: 0.62, Precision: 0.79, Recall: 0.55, PR AUC: 0.70\n",
      "Threshold: 0.63, Precision: 0.78, Recall: 0.54, PR AUC: 0.70\n",
      "Threshold: 0.64, Precision: 0.79, Recall: 0.53, PR AUC: 0.70\n",
      "Threshold: 0.65, Precision: 0.78, Recall: 0.53, PR AUC: 0.70\n",
      "Threshold: 0.66, Precision: 0.78, Recall: 0.52, PR AUC: 0.70\n",
      "Threshold: 0.67, Precision: 0.78, Recall: 0.51, PR AUC: 0.70\n",
      "Threshold: 0.68, Precision: 0.79, Recall: 0.51, PR AUC: 0.70\n",
      "Threshold: 0.69, Precision: 0.79, Recall: 0.51, PR AUC: 0.70\n",
      "Threshold: 0.70, Precision: 0.79, Recall: 0.50, PR AUC: 0.70\n",
      "Threshold: 0.71, Precision: 0.79, Recall: 0.50, PR AUC: 0.70\n",
      "Threshold: 0.72, Precision: 0.80, Recall: 0.49, PR AUC: 0.70\n",
      "Threshold: 0.73, Precision: 0.80, Recall: 0.48, PR AUC: 0.70\n",
      "Threshold: 0.74, Precision: 0.81, Recall: 0.48, PR AUC: 0.70\n",
      "Threshold: 0.75, Precision: 0.82, Recall: 0.46, PR AUC: 0.70\n",
      "Threshold: 0.76, Precision: 0.83, Recall: 0.46, PR AUC: 0.70\n",
      "Threshold: 0.77, Precision: 0.84, Recall: 0.45, PR AUC: 0.70\n",
      "Threshold: 0.78, Precision: 0.84, Recall: 0.44, PR AUC: 0.70\n",
      "Threshold: 0.79, Precision: 0.84, Recall: 0.43, PR AUC: 0.70\n",
      "Threshold: 0.80, Precision: 0.84, Recall: 0.41, PR AUC: 0.70\n",
      "Threshold: 0.81, Precision: 0.84, Recall: 0.40, PR AUC: 0.70\n",
      "Threshold: 0.82, Precision: 0.84, Recall: 0.38, PR AUC: 0.70\n",
      "Threshold: 0.83, Precision: 0.84, Recall: 0.38, PR AUC: 0.70\n",
      "Threshold: 0.84, Precision: 0.85, Recall: 0.36, PR AUC: 0.70\n",
      "Threshold: 0.85, Precision: 0.85, Recall: 0.35, PR AUC: 0.70\n",
      "Threshold: 0.86, Precision: 0.86, Recall: 0.34, PR AUC: 0.70\n",
      "Threshold: 0.87, Precision: 0.87, Recall: 0.32, PR AUC: 0.70\n",
      "Threshold: 0.88, Precision: 0.86, Recall: 0.30, PR AUC: 0.70\n",
      "Threshold: 0.89, Precision: 0.87, Recall: 0.29, PR AUC: 0.70\n",
      "Threshold: 0.90, Precision: 0.86, Recall: 0.27, PR AUC: 0.70\n",
      "Threshold: 0.91, Precision: 0.88, Recall: 0.26, PR AUC: 0.70\n",
      "Threshold: 0.92, Precision: 0.87, Recall: 0.23, PR AUC: 0.70\n",
      "Threshold: 0.93, Precision: 0.89, Recall: 0.22, PR AUC: 0.70\n",
      "Threshold: 0.94, Precision: 0.88, Recall: 0.19, PR AUC: 0.70\n",
      "Threshold: 0.95, Precision: 0.87, Recall: 0.15, PR AUC: 0.70\n",
      "Threshold: 0.96, Precision: 0.87, Recall: 0.13, PR AUC: 0.70\n",
      "Threshold: 0.97, Precision: 0.88, Recall: 0.09, PR AUC: 0.70\n",
      "Threshold: 0.98, Precision: 0.89, Recall: 0.06, PR AUC: 0.70\n",
      "Threshold: 0.99, Precision: 0.95, Recall: 0.05, PR AUC: 0.70\n"
     ]
    }
   ],
   "source": [
    "for thr in np.arange(0, 1.0, 0.01):\n",
    "    y_pred = (y_probs >= thr).astype(int)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    pr_auc = average_precision_score(y_val, y_probs)\n",
    "    print(f\"Threshold: {thr:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, PR AUC: {pr_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0dff588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 0s 580us/step\n",
      "[[7582  499]\n",
      " [  63  370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      8081\n",
      "           1       0.43      0.85      0.57       433\n",
      "\n",
      "    accuracy                           0.93      8514\n",
      "   macro avg       0.71      0.90      0.77      8514\n",
      "weighted avg       0.96      0.93      0.94      8514\n",
      "\n",
      "PR AUC: 0.7087053164710877\n"
     ]
    }
   ],
   "source": [
    "y_probs = model.predict(X_test_scaled)\n",
    "y_pred = (y_probs > 0.05).astype(\"int32\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "pr_auc = average_precision_score(y_test, y_probs)\n",
    "print(\"PR AUC:\", pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a175dfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Metrics for Filename -> Precision: 0.426, Recall: 0.855\n"
     ]
    }
   ],
   "source": [
    "test_precision = precision_score(y_test, y_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Set Metrics for Filename -> Precision: {test_precision:.3f}, Recall: {test_recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dec15eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: model_prauc_0.709_thresh_0.210_prec_0.426_rec_0.855.keras\n",
      "Saving scaler to: scaler_prauc_0.709_thresh_0.210_prec_0.426_rec_0.855.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler_prauc_0.709_thresh_0.210_prec_0.426_rec_0.855.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_filename = (\n",
    "    f\"prauc_{pr_auc:.3f}_\"\n",
    "    f\"thresh_{best_threshold:.3f}_\"\n",
    "    f\"prec_{test_precision:.3f}_\"\n",
    "    f\"rec_{test_recall:.3f}\"\n",
    ")\n",
    "\n",
    "model_filename = f\"model_{base_filename}.keras\"\n",
    "scaler_filename = f\"scaler_{base_filename}.pkl\"\n",
    "\n",
    "print(f\"Saving model to: {model_filename}\")\n",
    "model.save(model_filename)\n",
    "print(f\"Saving scaler to: {scaler_filename}\")\n",
    "joblib.dump(scaler, scaler_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4ed300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from models/match_tuning/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "# 1. Create a model-building function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    hp_units_1 = hp.Int('units_1', min_value=32, max_value=1024, step=32)\n",
    "    model.add(Dense(units=hp_units_1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # Tune the dropout rate\n",
    "    hp_dropout_1 = hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(hp_dropout_1))\n",
    "\n",
    "    # Add another tunable hidden layer\n",
    "    hp_units_2 = hp.Int('units_2', min_value=32, max_value=512, step=32)\n",
    "    model.add(Dense(units=hp_units_2, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    hp_dropout_2 = hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(hp_dropout_2))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])\n",
    "    \n",
    "    pr_auc = AUC(curve=\"PR\", name=\"pr_auc\")\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[pr_auc])\n",
    "    return model\n",
    "\n",
    "# 2. Instantiate the tuner\n",
    "# We'll use Hyperband, an efficient algorithm for finding good hyperparameters\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective=kt.Objective(\"val_pr_auc\", direction=\"max\"), # Your key metric\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='models',\n",
    "                     project_name='match_tuning')\n",
    "\n",
    "# Define an early stopping callback to prevent wasting time on bad trials\n",
    "stop_early = EarlyStopping(monitor='val_pr_auc', mode='max', patience=5)\n",
    "\n",
    "# 3. Run the search\n",
    "tuner.search(X_train_scaled, y_train,\n",
    "             epochs=50,\n",
    "             validation_data=(X_val_scaled, y_val),\n",
    "             callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d1938f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete.\n",
      "Optimal units in first layer: 96\n",
      "Optimal dropout in first layer: 0.4\n",
      "Optimal units in second layer: 64\n",
      "Optimal dropout in second layer: 0.30000000000000004\n",
      "Optimal learning rate: 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "Optimal units in first layer: {best_hps.get('units_1')}\n",
    "Optimal dropout in first layer: {best_hps.get('dropout_1')}\n",
    "Optimal units in second layer: {best_hps.get('units_2')}\n",
    "Optimal dropout in second layer: {best_hps.get('dropout_2')}\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "228e9eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2129/2129 [==============================] - 6s 3ms/step - loss: 0.2155 - pr_auc: 0.1128 - val_loss: 0.1320 - val_pr_auc: 0.4029\n",
      "Epoch 2/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.1404 - pr_auc: 0.3759 - val_loss: 0.1145 - val_pr_auc: 0.4990\n",
      "Epoch 3/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.1232 - pr_auc: 0.4823 - val_loss: 0.1060 - val_pr_auc: 0.5616\n",
      "Epoch 4/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.1129 - pr_auc: 0.5360 - val_loss: 0.1003 - val_pr_auc: 0.5991\n",
      "Epoch 5/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.1054 - pr_auc: 0.5835 - val_loss: 0.0936 - val_pr_auc: 0.6335\n",
      "Epoch 6/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0982 - pr_auc: 0.6273 - val_loss: 0.0932 - val_pr_auc: 0.6313\n",
      "Epoch 7/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0942 - pr_auc: 0.6557 - val_loss: 0.0927 - val_pr_auc: 0.6522\n",
      "Epoch 8/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0907 - pr_auc: 0.6731 - val_loss: 0.0929 - val_pr_auc: 0.6416\n",
      "Epoch 9/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0865 - pr_auc: 0.6948 - val_loss: 0.0933 - val_pr_auc: 0.6581\n",
      "Epoch 10/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0847 - pr_auc: 0.7065 - val_loss: 0.0914 - val_pr_auc: 0.6661\n",
      "Epoch 11/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0806 - pr_auc: 0.7227 - val_loss: 0.0912 - val_pr_auc: 0.6771\n",
      "Epoch 12/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0781 - pr_auc: 0.7452 - val_loss: 0.0920 - val_pr_auc: 0.6622\n",
      "Epoch 13/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0782 - pr_auc: 0.7421 - val_loss: 0.0893 - val_pr_auc: 0.6833\n",
      "Epoch 14/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0744 - pr_auc: 0.7604 - val_loss: 0.0897 - val_pr_auc: 0.6740\n",
      "Epoch 15/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0710 - pr_auc: 0.7782 - val_loss: 0.0914 - val_pr_auc: 0.6760\n",
      "Epoch 16/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0714 - pr_auc: 0.7730 - val_loss: 0.0943 - val_pr_auc: 0.6635\n",
      "Epoch 17/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0678 - pr_auc: 0.7936 - val_loss: 0.0938 - val_pr_auc: 0.6609\n",
      "Epoch 18/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0669 - pr_auc: 0.7988 - val_loss: 0.0906 - val_pr_auc: 0.6917\n",
      "Epoch 19/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0658 - pr_auc: 0.8028 - val_loss: 0.0942 - val_pr_auc: 0.6699\n",
      "Epoch 20/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0637 - pr_auc: 0.8173 - val_loss: 0.0913 - val_pr_auc: 0.6901\n",
      "Epoch 21/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0635 - pr_auc: 0.8128 - val_loss: 0.0950 - val_pr_auc: 0.6758\n",
      "Epoch 22/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0618 - pr_auc: 0.8243 - val_loss: 0.0930 - val_pr_auc: 0.6922\n",
      "Epoch 23/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0612 - pr_auc: 0.8285 - val_loss: 0.0960 - val_pr_auc: 0.6720\n",
      "Epoch 24/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0598 - pr_auc: 0.8329 - val_loss: 0.0922 - val_pr_auc: 0.6974\n",
      "Epoch 25/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0582 - pr_auc: 0.8408 - val_loss: 0.0925 - val_pr_auc: 0.6997\n",
      "Epoch 26/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0569 - pr_auc: 0.8471 - val_loss: 0.1030 - val_pr_auc: 0.6741\n",
      "Epoch 27/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0556 - pr_auc: 0.8524 - val_loss: 0.0963 - val_pr_auc: 0.6846\n",
      "Epoch 28/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0556 - pr_auc: 0.8537 - val_loss: 0.1005 - val_pr_auc: 0.6747\n",
      "Epoch 29/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0543 - pr_auc: 0.8603 - val_loss: 0.0944 - val_pr_auc: 0.6909\n",
      "Epoch 30/50\n",
      "2129/2129 [==============================] - 4s 2ms/step - loss: 0.0549 - pr_auc: 0.8572 - val_loss: 0.0958 - val_pr_auc: 0.6888\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train_scaled, y_train, epochs=50, validation_data=(X_val_scaled, y_val), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ca382cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models hyperparameters on a .txt with the same base_filename\n",
    "hyperparams = f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "Optimal units in first layer: {best_hps.get('units_1')}\n",
    "Optimal dropout in first layer: {best_hps.get('dropout_1')}\n",
    "Optimal units in second layer: {best_hps.get('units_2')}\n",
    "Optimal dropout in second layer: {best_hps.get('dropout_2')}\n",
    "Optimal learning rate: {best_hps.get('learning_rate')}\n",
    "\"\"\"\n",
    "with open(f\"hyperparams_{base_filename}.txt\", \"w\") as f:\n",
    "    f.write(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78f6f760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3427, number of negative: 64681\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.462660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497459\n",
      "[LightGBM] [Info] Number of data points in the train set: 68108, number of used features: 6629\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.050317 -> initscore=-2.937782\n",
      "[LightGBM] [Info] Start training from score -2.937782\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's average_precision: 0.271302\tvalid_0's binary_logloss: 0.183753\n",
      "[20]\tvalid_0's average_precision: 0.282293\tvalid_0's binary_logloss: 0.182261\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's average_precision: 0.281686\tvalid_0's binary_logloss: 0.182231\n",
      "\n",
      "Best Threshold for LightGBM (F2-score): 0.0983\n",
      "\n",
      "--- LightGBM Performance on Test Set ---\n",
      "[[7184  897]\n",
      " [ 139  294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      8081\n",
      "           1       0.25      0.68      0.36       433\n",
      "\n",
      "    accuracy                           0.88      8514\n",
      "   macro avg       0.61      0.78      0.65      8514\n",
      "weighted avg       0.94      0.88      0.90      8514\n",
      "\n",
      "PR AUC: 0.27699335949326925\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "neg = (y_train == 0).sum()\n",
    "pos = (y_train == 1).sum()\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "# 1. Initialize and train the LightGBM model\n",
    "# Use is_unbalanced=True to let the model handle the class imbalance.\n",
    "# Train on the original (but scaled) training data, NOT the SMOTE'd data.\n",
    "lgbm = lgb.LGBMClassifier(objective='binary',\n",
    "                          n_estimators=1000,\n",
    "                          learning_rate=0.005,\n",
    "                          random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "# Train the model\n",
    "lgbm.fit(X_train, y_train,\n",
    "         eval_set=[(X_val, y_val)],\n",
    "         eval_metric=\"average_precision\",\n",
    "         callbacks=[\n",
    "             lgb.early_stopping(stopping_rounds=10), # Added stopping_rounds for clarity\n",
    "             lgb.log_evaluation(period=10)            # This is the line that fixes the error\n",
    "         ])\n",
    "\n",
    "\n",
    "# 2. Find the optimal threshold for LightGBM on the validation set (same as you did for the NN)\n",
    "y_probs_lgbm_val = lgbm.predict_proba(X_val)[:, 1]\n",
    "prec_lgbm, rec_lgbm, thresholds_lgbm = precision_recall_curve(y_val, y_probs_lgbm_val)\n",
    "f2_scores_lgbm = (5 * prec_lgbm * rec_lgbm) / (4 * prec_lgbm + rec_lgbm + 1e-9)\n",
    "best_threshold_lgbm = thresholds_lgbm[np.argmax(f2_scores_lgbm)]\n",
    "\n",
    "print(f\"\\nBest Threshold for LightGBM (F2-score): {best_threshold_lgbm:.4f}\")\n",
    "\n",
    "# Evaluate on the test set with the optimized threshold\n",
    "y_probs_lgbm_test = lgbm.predict_proba(X_test)[:, 1]\n",
    "y_pred_lgbm_test = (y_probs_lgbm_test >= best_threshold_lgbm).astype(int)\n",
    "\n",
    "print(\"\\n--- LightGBM Performance on Test Set ---\")\n",
    "print(confusion_matrix(y_test, y_pred_lgbm_test))\n",
    "print(classification_report(y_test, y_pred_lgbm_test))\n",
    "print(\"PR AUC:\", average_precision_score(y_test, y_probs_lgbm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34421098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Random Forest ---\n",
      "\n",
      "Best Threshold for Random Forest (F2-score): 0.1000\n",
      "\n",
      "--- Random Forest Performance on Test Set ---\n",
      "[[7592  489]\n",
      " [ 133  300]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      8081\n",
      "           1       0.38      0.69      0.49       433\n",
      "\n",
      "    accuracy                           0.93      8514\n",
      "   macro avg       0.68      0.82      0.73      8514\n",
      "weighted avg       0.95      0.93      0.94      8514\n",
      "\n",
      "PR AUC: 0.44253688325846163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n",
    "\n",
    "# 1. Initialize and train the Random Forest model\n",
    "print(\"--- Training Random Forest ---\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,          # The number of trees in the forest\n",
    "    class_weight='balanced',   # Handles class imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1                  # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Train on the original (un-SMOTEd) data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 2. Find the optimal threshold on the validation set\n",
    "y_probs_rf_val = rf.predict_proba(X_val)[:, 1]\n",
    "prec_rf, rec_rf, thresholds_rf = precision_recall_curve(y_val, y_probs_rf_val)\n",
    "f2_scores_rf = (5 * prec_rf * rec_rf) / (4 * prec_rf + rec_rf + 1e-9)\n",
    "best_threshold_rf = thresholds_rf[np.argmax(f2_scores_rf)]\n",
    "\n",
    "print(f\"\\nBest Threshold for Random Forest (F2-score): {best_threshold_rf:.4f}\")\n",
    "\n",
    "# 3. Evaluate on the test set with the optimized threshold\n",
    "y_probs_rf_test = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf_test = (y_probs_rf_test >= best_threshold_rf).astype(int)\n",
    "\n",
    "print(\"\\n--- Random Forest Performance on Test Set ---\")\n",
    "print(confusion_matrix(y_test, y_pred_rf_test))\n",
    "print(classification_report(y_test, y_pred_rf_test))\n",
    "print(\"PR AUC:\", average_precision_score(y_test, y_probs_rf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fbfc2bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training XGBoost ---\n",
      "\n",
      "Best Threshold for XGBoost (F2-score): 0.0496\n",
      "\n",
      "--- XGBoost Performance on Test Set ---\n",
      "[[7692  389]\n",
      " [ 116  317]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      8081\n",
      "           1       0.45      0.73      0.56       433\n",
      "\n",
      "    accuracy                           0.94      8514\n",
      "   macro avg       0.72      0.84      0.76      8514\n",
      "weighted avg       0.96      0.94      0.95      8514\n",
      "\n",
      "PR AUC: 0.5720201585437346\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1. Calculate the weight for the positive class\n",
    "# ratio of negative samples to positive samples\n",
    "scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "\n",
    "# 2. Initialize and train the XGBoost model\n",
    "print(\"\\n--- Training XGBoost ---\")\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='aucpr',\n",
    "    scale_pos_weight=scale_pos_weight, # Handles class imbalance\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model with early stopping\n",
    "xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False  # Set to True to see training progress\n",
    ")\n",
    "\n",
    "# 3. Find the optimal threshold on the validation set\n",
    "y_probs_xgb_val = xgb.predict_proba(X_val)[:, 1]\n",
    "prec_xgb, rec_xgb, thresholds_xgb = precision_recall_curve(y_val, y_probs_xgb_val)\n",
    "f2_scores_xgb = (5 * prec_xgb * rec_xgb) / (4 * prec_xgb + rec_xgb + 1e-9)\n",
    "best_threshold_xgb = thresholds_xgb[np.argmax(f2_scores_xgb)]\n",
    "\n",
    "print(f\"\\nBest Threshold for XGBoost (F2-score): {best_threshold_xgb:.4f}\")\n",
    "\n",
    "# 4. Evaluate on the test set with the optimized threshold\n",
    "y_probs_xgb_test = xgb.predict_proba(X_test)[:, 1]\n",
    "y_pred_xgb_test = (y_probs_xgb_test >= best_threshold_xgb).astype(int)\n",
    "\n",
    "print(\"\\n--- XGBoost Performance on Test Set ---\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb_test))\n",
    "print(classification_report(y_test, y_pred_xgb_test))\n",
    "print(\"PR AUC:\", average_precision_score(y_test, y_probs_xgb_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a20e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 0s 630us/step\n",
      "Prediction results have been prepared.\n",
      "\n",
      "You can inspect the following need_ids from the test set:\n",
      "[ 4618  8288   326 12015   765  4208   931  5552  4698   367  3493  5112\n",
      " 11388  1419  1684  5444  1906 12418 11355  3877  4116   325  3202 10531\n",
      " 12609  5056   163 14622 17955  4231   531 11558 12081  4657  2103  4822\n",
      "  1003  6867 17493 18087  3909   964  1972  1167 14919  5278  3680   607\n",
      "  1126  2762   949  2757   644   514  4325 18149   331  3326   610  4550\n",
      "  2302  3047  4151  4040  5514   932  5352  2316 16569  5189  5001  4175\n",
      "  4898 10497  1925   630  3225  1192  2525 17757  5371  5621  3169   577\n",
      "  8716   370  2432  5641  2190  5353  1127   849  4485 16404  5163  3522\n",
      " 17597  5201 12807 17692  1461  4063 10333  1747  4447  2593  5072  3824\n",
      "  3128   995  2752  4190  1797    36  2590 12840 14688  1838  3875  5354\n",
      " 12775  4604  4742  5094  3726   407  5159  5522  3408  3434  5466 17988\n",
      "  3293 17889  5095   113  3427   551  2591   467  3882 13116 16075  4658\n",
      "   994  7165  4563  5745  5103  3072  5297  2126  1278  3531  4010  3021\n",
      " 10860   888   756  5476 10861  2201   476 12708  1464  5560  2669  1466\n",
      "  4085  1527  1963 13104   712  1131 13137  1846  5460  4425   613  4181\n",
      "  4298  1344  1352  2441  5156  2855 15746  4295  1019   807  2576    63\n",
      "  4897   198  4923  7799  6109   429  5061 15183  3510   393  1426  5147\n",
      "  1518  7798 17132  2111  4160 11563  4896  1222  5171 12114    97  4318\n",
      "  5333  2980   363  1483  3327  4571  6604 15977  1017  4599  3285  1536\n",
      " 16076  4824  3428  8055   179  5214   759  9640  1336  4745  4133 17035\n",
      "  4179 11916  3579    39  1084  1347 12183  1189  3871  5627  3903  4029\n",
      "  4947  1546  4935 14523 18153  1604   505  2186  1044   119 14590   468\n",
      "   604  2440   123  2030  1080  3120  5064   431  4052  2944  1290   108\n",
      "  5532 12180  3199  3608  4365 14856  5252  2267  7725  7528  2422  1506\n",
      " 16470   417   295   816  1180  8352  4207   667  1568  4878   794  4905\n",
      "  3691  1364  1921  1717  4323  1924  1830  4778 17131  4051  4100  1918\n",
      "  3339   871  2769  7800  2683  1544 17791   222  1122  3468   293  5059\n",
      "  4642  1348  5063   522 15084  4317 12741  3688   958  4648  1346  4054\n",
      "  4927  5114   998  3193   204  1049  8319 17790  1103  4220  4546   879\n",
      "  5236  9705 11555 10301  2521  3054  9015  2979  3357   782   956  1115\n",
      "  1908  1503  1064  1526  1909  5338   249  5192    72 14028  1476 16041\n",
      "  3226   558  2597   474  5366  2429  2885   779  3532  5432  2448  5335\n",
      "  4888   488  1651  8291  1288 11125  3516   127  4975  4293 14556   466\n",
      "   125  5506  4738  8847  1010  4877   572   333  5643  2902  4655  3826\n",
      "  5433   418  1181  4864   298]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Preparation: Create the Results DataFrame (Run this once) ---\n",
    "# This example uses your champion Neural Network model.\n",
    "# You can swap 'model' with 'xgb' or another trained model to see its predictions.\n",
    "\n",
    "# Get predictions on the test set using your best model and threshold\n",
    "y_probs_test = model.predict(X_test_scaled)\n",
    "y_pred_test = (y_probs_test > best_threshold).astype(int) # Use the threshold you found for the NN\n",
    "\n",
    "# Create a DataFrame with predictions linked back to the original data\n",
    "results_df = merged.loc[X_test.index].copy()\n",
    "results_df['has_match'] = y_test\n",
    "results_df['probability'] = y_probs_test\n",
    "results_df['prediction'] = y_pred_test\n",
    "\n",
    "# Select the most relevant columns for a clean view\n",
    "view_cols = ['need_id', 'need_name', 'offer_name', 'name', 'has_match', 'prediction', 'probability']\n",
    "final_results = results_df[view_cols]\n",
    "\n",
    "print(\"Prediction results have been prepared.\")\n",
    "\n",
    "\n",
    "# --- 2. The Interactive Function ---\n",
    "def display_need_predictions(need_id, results_df):\n",
    "    \"\"\"\n",
    "    Displays a summary of model predictions for a specific need_id,\n",
    "    sorted by probability.\n",
    "    \"\"\"\n",
    "    # Filter the results for the specified need_id\n",
    "    group = results_df[results_df['need_id'] == need_id]\n",
    "\n",
    "    # Check if the need_id exists in the test set results\n",
    "    if group.empty:\n",
    "        print(f\"Sorry, Need ID: {need_id} was not found in the test set.\")\n",
    "        return\n",
    "\n",
    "    # Sort the results by the model's predicted probability\n",
    "    group = group.sort_values('probability', ascending=False)\n",
    "    \n",
    "    need_name = group['need_name'].iloc[0]\n",
    "    \n",
    "    print(f\"\\n--- Predictions for Need ID: {need_id} ({need_name[:50]}...) ---\")\n",
    "    \n",
    "    # Calculate summary stats for this need\n",
    "    true_matches = group['has_match'].sum()\n",
    "    predicted_matches = group['prediction'].sum()\n",
    "    correctly_predicted = group[(group['has_match'] == 1) & (group['prediction'] == 1)].shape[0]\n",
    "\n",
    "    print(f\"Summary: The model found {correctly_predicted} of the {true_matches} true matches for this need.\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Print the ranked list of potential offers for this need\n",
    "    print(group[['offer_name', 'name', 'has_match', 'prediction', 'probability']].to_string(index=False))\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# --- 3. How to Use the Function ---\n",
    "\n",
    "# First, find some interesting need_ids to inspect from your test set\n",
    "# (e.g., ones that we know have at least one true match)\n",
    "needs_with_matches_in_test = final_results[final_results['has_match'] == 1]['need_id'].unique()\n",
    "print(\"\\nYou can inspect the following need_ids from the test set:\")\n",
    "print(needs_with_matches_in_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a28c65c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predictions for Need ID: 4179 (Identificación y reconocimiento histórico de áreas...) ---\n",
      "Summary: The model found 0 of the 1 true matches for this need.\n",
      "--------------------------------------------------------------------------------\n",
      "                   offer_name                name  has_match  prediction  probability\n",
      "              Pasantía 2-2022 Geografía_Prácticas          1           0 8.184763e-04\n",
      "Gestión de Operaciones 2-2022          Cluster 54          0           0 1.882446e-08\n",
      "             Ergonomia 1-2023          Cluster 74          0           0 8.812553e-09\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Predictions for Need ID: 1717 (Gestión del proceso de provisión de bienes y servi...) ---\n",
      "Summary: The model found 0 of the 1 true matches for this need.\n",
      "--------------------------------------------------------------------------------\n",
      "                                                    offer_name                       name  has_match  prediction  probability\n",
      "                                    Modelos de procesos 2-2019           Cluster Procesos          1           0 6.285564e-03\n",
      "                                       Pasantía derecho 2-2019                 Cluster 47          0           0 1.381117e-03\n",
      "                                               Pasantía 2-2021 Ciencia Política_Prácticas          0           0 1.510755e-05\n",
      "Desarrollo de Habilidades Comunicativas para Ingenieros 2-2019                Cluster 110          0           0 5.962123e-06\n",
      "                                   Práctica Profesional 2-2019       Ingeniería_Prácticas          0           0 5.839005e-07\n",
      "                                      Derecho Ambiental 2-2019          Derecho_Ambiental          0           0 3.978463e-07\n",
      "                                               Pasantía 2-2021              Bio_Prácticas          0           0 2.155855e-07\n",
      "        Intervención de Enfermería en Salud Comunitaria 2-2019     Enfermería_Comunitaria          0           0 3.770312e-08\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, call the function with a need_id of your choice\n",
    "# Example:\n",
    "display_need_predictions(4179, final_results)\n",
    "display_need_predictions(1717, final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12f50c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following need_ids had at least one true match that the model failed to predict:\n",
      "[ 3493  1419  4116   325  5056   531  2103  4822  6867  1126   610  2302\n",
      "  3225  1192  5641  2190  1127   849  4485 12807    36  2590 12775  4742\n",
      "  5522  5466   113  5297  1278   888  2201   476   613  1352  2855    63\n",
      "   198  3510 11563  1483   179  4179  1604  2186  1044  3120  2944  1290\n",
      "  3608  1180  1568   794  1717  4323  1924  2769  2683  4642  4648  4927\n",
      "  1049 11555  3054  9015  1115   249  5192  2597  5366   779  3532  5432\n",
      "  2448  1651 11125   127  4293   125  1010  5643  5433]\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows that are False Negatives (True Match = 1, Predicted = 0)\n",
    "missed_matches_df = final_results[(final_results['has_match'] == 1) & (final_results['prediction'] == 0)]\n",
    "\n",
    "# Get a unique list of the need_ids from that filtered DataFrame\n",
    "needs_with_missed_matches = missed_matches_df['need_id'].unique()\n",
    "\n",
    "print(\"The following need_ids had at least one true match that the model failed to predict:\")\n",
    "print(needs_with_missed_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a99e44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>need_id</th>\n",
       "      <th>need_name</th>\n",
       "      <th>offer_name</th>\n",
       "      <th>name</th>\n",
       "      <th>has_match</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>3493</td>\n",
       "      <td>Propuestas para aumentar movilidad sostenible ...</td>\n",
       "      <td>Movilidad Sostenible y Ciclo-Inclusión Como Re...</td>\n",
       "      <td>Cluster 136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>1419</td>\n",
       "      <td>Diseño del departamento municipal de la inter...</td>\n",
       "      <td>Proyecto de titulación Magister CP 1-2019</td>\n",
       "      <td>Cluster 142</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>4116</td>\n",
       "      <td>Talleres Cuidado y Bienestar Vocal para Educad...</td>\n",
       "      <td>Pasantía de Fonoaudiología 2-2022</td>\n",
       "      <td>Cluster 111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>325</td>\n",
       "      <td>Modelo de costeo de prestaciones para prioriza...</td>\n",
       "      <td>Práctica Profesional Verano-2017</td>\n",
       "      <td>Comercial_Prácticas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>5056</td>\n",
       "      <td>Diagnóstico para la implementación de sistemas...</td>\n",
       "      <td>Sistemas de Información 1-2023</td>\n",
       "      <td>Cluster 80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      need_id                                          need_name  \\\n",
       "274      3493  Propuestas para aumentar movilidad sostenible ...   \n",
       "379      1419   Diseño del departamento municipal de la inter...   \n",
       "3742     4116  Talleres Cuidado y Bienestar Vocal para Educad...   \n",
       "848       325  Modelo de costeo de prestaciones para prioriza...   \n",
       "419      5056  Diagnóstico para la implementación de sistemas...   \n",
       "\n",
       "                                             offer_name                 name  \\\n",
       "274   Movilidad Sostenible y Ciclo-Inclusión Como Re...          Cluster 136   \n",
       "379           Proyecto de titulación Magister CP 1-2019          Cluster 142   \n",
       "3742                  Pasantía de Fonoaudiología 2-2022          Cluster 111   \n",
       "848                    Práctica Profesional Verano-2017  Comercial_Prácticas   \n",
       "419                      Sistemas de Información 1-2023           Cluster 80   \n",
       "\n",
       "      has_match  prediction  probability  \n",
       "274           1           0     0.008588  \n",
       "379           1           0     0.024479  \n",
       "3742          1           0     0.004254  \n",
       "848           1           0     0.028921  \n",
       "419           1           0     0.000306  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_matches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd06ac9-37ff-4d38-aab5-3a23f96d234f",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "puentes_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
